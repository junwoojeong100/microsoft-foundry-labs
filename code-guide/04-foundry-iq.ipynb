{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433dbf79",
   "metadata": {},
   "source": [
    "> âš ï¸ **ì‘ì—… ì¤‘ (Work in Progress)**: ì´ ë…¸íŠ¸ë¶ì€ í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. ì¼ë¶€ ì½”ë“œê°€ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d5c27",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ëª©ì°¨\n",
    "\n",
    "- [Foundry IQ ê°œìš”](#foundry-iq-ê°œìš”)\n",
    "- [AI Search ì—°ê²°](#ai-search-ì—°ê²°)\n",
    "- [Knowledge Base ìƒì„± (AI Search Index)](#knowledge-base-ìƒì„±-ai-search-index)\n",
    "- [Knowledge Base ìƒì„± (Blob Storage)](#knowledge-base-ìƒì„±-blob-storage)\n",
    "- [KnowledgeAgent í†µí•©](#knowledgeagent-í†µí•©)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572243f1",
   "metadata": {},
   "source": [
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- Foundry IQì˜ ê°œë…ê³¼ ì¥ì  ì´í•´\n",
    "- Azure AI Search ë¦¬ì†ŒìŠ¤ ì—°ê²° ë° êµ¬ì„±\n",
    "- AI Search Index ê¸°ë°˜ Knowledge Base ìƒì„±\n",
    "- Blob Storage ê¸°ë°˜ Knowledge Base\n",
    "- Knowledge Baseë¥¼ ì—ì´ì „íŠ¸ì— í†µí•©í•˜ëŠ” ë°©ë²• í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba2220",
   "metadata": {},
   "source": [
    "## â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„\n",
    "\n",
    "ì•½ 40ë¶„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e0f68",
   "metadata": {},
   "source": [
    "## Foundry IQ ê°œìš”\n",
    "\n",
    "### Foundry IQë€?\n",
    "\n",
    "Foundry IQëŠ” Microsoft Foundryì˜ ì§€ëŠ¥í˜• ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ AI ì—ì´ì „íŠ¸ì— ë§¥ë½ì  ì§€ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” íŠ¹ì§•\n",
    "\n",
    "```\n",
    "Foundry IQ = Retrieval + Reasoning + Ranking\n",
    "```\n",
    "\n",
    "- **Retrieval**: ê´€ë ¨ ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰\n",
    "- **Reasoning**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì´í•´í•˜ê³  í•´ì„\n",
    "- **Ranking**: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë¥¼ ìš°ì„ ìˆœìœ„í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769d135",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •\n",
    "\n",
    "Knowledge Base êµ¬ì¶•ì„ ìœ„í•œ Azure ë¦¬ì†ŒìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2f2a2",
   "metadata": {},
   "source": [
    "### Azure í™˜ê²½ ë³€ìˆ˜ ë° íŒ¨í‚¤ì§€ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# PATH í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Azure CLIë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡)\n",
    "possible_paths = [\n",
    "    \"/opt/homebrew/bin\",  # macOS (Apple Silicon)\n",
    "    \"/usr/local/bin\",     # macOS (Intel) / Linux\n",
    "    \"/usr/bin\",           # Linux / GitHub Codespaces\n",
    "    \"/home/linuxbrew/.linuxbrew/bin\"  # Linux Homebrew\n",
    "]\n",
    "\n",
    "az_path = None\n",
    "try:\n",
    "    result = subprocess.run(['which', 'az'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        az_path = os.path.dirname(result.stdout.strip())\n",
    "except:\n",
    "    pass\n",
    "\n",
    "paths_to_add = []\n",
    "if az_path and az_path not in os.environ.get(\"PATH\", \"\"):\n",
    "    paths_to_add.append(az_path)\n",
    "else:\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path) and path not in os.environ.get(\"PATH\", \"\"):\n",
    "            paths_to_add.append(path)\n",
    "\n",
    "if paths_to_add:\n",
    "    new_path = \":\".join(paths_to_add) + \":\" + os.environ.get(\"PATH\", \"\")\n",
    "    os.environ[\"PATH\"] = new_path\n",
    "\n",
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ì €ì¥í•œ ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "config_file = \".foundry_config.json\"\n",
    "try:\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "    FOUNDRY_NAME = config.get(\"FOUNDRY_NAME\")\n",
    "    RESOURCE_GROUP = config.get(\"RESOURCE_GROUP\")\n",
    "    LOCATION = config.get(\"LOCATION\")\n",
    "    TENANT_ID = config.get(\"TENANT_ID\")\n",
    "    PROJECT_NAME = config.get(\"PROJECT_NAME\", \"proj-default\")\n",
    "    PROJECT_ENDPOINT = config.get(\"FOUNDRY_ENDPOINT\")\n",
    "    \n",
    "    # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • (ë‹¤ë¥¸ ë„êµ¬ë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)\n",
    "    os.environ[\"FOUNDRY_NAME\"] = FOUNDRY_NAME\n",
    "    os.environ[\"LOCATION\"] = LOCATION\n",
    "    os.environ[\"RESOURCE_GROUP\"] = RESOURCE_GROUP\n",
    "    os.environ[\"AZURE_SUBSCRIPTION_ID\"] = config.get(\"AZURE_SUBSCRIPTION_ID\", \"\")\n",
    "    os.environ[\"_ENDPOINT\"] = PROJECT_ENDPOINT\n",
    "    \n",
    "    print(f\"âœ… ì„¤ì • íŒŒì¼ '{config_file}'ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"\\nğŸ“Œ Foundry Name: {FOUNDRY_NAME}\")\n",
    "    print(f\"ğŸ“Œ Resource Group: {RESOURCE_GROUP}\")\n",
    "    print(f\"ğŸ“Œ Location: {LOCATION}\")\n",
    "    print(f\"ğŸ“Œ í”„ë¡œì íŠ¸ ì—”ë“œí¬ì¸íŠ¸: {PROJECT_ENDPOINT}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âš ï¸ '{config_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ 01-setup.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ í™˜ê²½ì„ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install -q azure-ai-projects azure-identity azure-search-documents requests\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Project Client ì´ˆê¸°í™”\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ (URLì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„)\n",
    "# ì˜ˆ: https://foundry-xxx.services.ai.azure.com/api/projects/default-project\n",
    "# â†’ project_name = \"default-project\"\n",
    "import re\n",
    "match = re.search(r'/projects/([^/]+)$', PROJECT_ENDPOINT)\n",
    "if match:\n",
    "    project_name = match.group(1)\n",
    "else:\n",
    "    project_name = PROJECT_NAME  # fallback to config\n",
    "\n",
    "# Foundry URL (í”„ë¡œì íŠ¸ ë¶€ë¶„ ì œì™¸)\n",
    "foundry_base_url = PROJECT_ENDPOINT.rsplit('/projects/', 1)[0]\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_base_url,\n",
    "    credential=credential,\n",
    "    project_name=project_name\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‚¬ìš©í•  í”„ë¡œì íŠ¸ ì—”ë“œí¬ì¸íŠ¸: {PROJECT_ENDPOINT}\")\n",
    "print(f\"âœ… Project Client ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   Foundry: {foundry_base_url}\")\n",
    "print(f\"   Project: {project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4340a9f6",
   "metadata": {},
   "source": [
    "### AI Search ë° Storage ë¦¬ì†ŒìŠ¤ ì´ë¦„ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a92771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Search ë° Storage ë¦¬ì†ŒìŠ¤ ì´ë¦„ ì„¤ì •\n",
    "import re\n",
    "\n",
    "# ê³ ìœ í•œ ì´ë¦„ ìƒì„± (ì†Œë¬¸ì, ìˆ«ì, í•˜ì´í”ˆë§Œ í—ˆìš©)\n",
    "def sanitize_name(name, max_length=24):\n",
    "    \"\"\"ë¦¬ì†ŒìŠ¤ ì´ë¦„ì„ Azure ê·œì¹™ì— ë§ê²Œ ì •ë¦¬\"\"\"\n",
    "    # ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ì˜ìˆ«ìë§Œ ë‚¨ê¹€\n",
    "    clean = re.sub(r'[^a-z0-9]', '', name.lower())\n",
    "    return clean[:max_length]\n",
    "\n",
    "# FOUNDRY_NAME ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  ì´ë¦„ ìƒì„±\n",
    "base_name = sanitize_name(FOUNDRY_NAME)\n",
    "\n",
    "SEARCH_NAME = f\"{base_name}-search\"[:64]  # AI SearchëŠ” ìµœëŒ€ 64ì\n",
    "STORAGE_NAME = sanitize_name(base_name + \"store\", 24)  # StorageëŠ” ìµœëŒ€ 24ì, í•˜ì´í”ˆ ë¶ˆê°€\n",
    "SEARCH_INDEX_NAME = \"knowledge-index\"\n",
    "\n",
    "print(\"ğŸ“Œ ìƒì„±í•  ë¦¬ì†ŒìŠ¤ ì´ë¦„:\")\n",
    "print(f\"   AI Search: {SEARCH_NAME}\")\n",
    "print(f\"   Storage Account: {STORAGE_NAME}\")\n",
    "print(f\"   Search Index: {SEARCH_INDEX_NAME}\")\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ì— ì €ì¥\n",
    "config[\"SEARCH_NAME\"] = SEARCH_NAME\n",
    "config[\"STORAGE_NAME\"] = STORAGE_NAME\n",
    "config[\"SEARCH_INDEX_NAME\"] = SEARCH_INDEX_NAME\n",
    "\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… ë¦¬ì†ŒìŠ¤ ì´ë¦„ì´ '{config_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80dd421",
   "metadata": {},
   "source": [
    "## Azure AI Search ìƒì„±\n",
    "\n",
    "ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ AI Search ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708491d5",
   "metadata": {},
   "source": [
    "### AI Search ë¦¬ì†ŒìŠ¤ ìƒì„± ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad435de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Search ë¦¬ì†ŒìŠ¤ ìƒì„±\n",
    "!az search service create \\\n",
    "    --name $SEARCH_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --location $LOCATION \\\n",
    "    --sku basic\n",
    "\n",
    "print(f\"\\nâœ… AI Search ìƒì„± ì™„ë£Œ: {SEARCH_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e13304",
   "metadata": {},
   "source": [
    "## Blob Storage ìƒì„±\n",
    "\n",
    "ë¬¸ì„œ íŒŒì¼ì„ ì €ì¥í•  Blob Storageë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc15bb",
   "metadata": {},
   "source": [
    "### Storage Account ë° Container ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage Account ìƒì„±\n",
    "!az storage account create \\\n",
    "    --name $STORAGE_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --location $LOCATION \\\n",
    "    --sku Standard_LRS \\\n",
    "    --public-network-access Enabled\n",
    "\n",
    "print(f\"\\nâœ… Storage Account ìƒì„± ì™„ë£Œ: {STORAGE_NAME}\")\n",
    "\n",
    "# Storage Container ìƒì„±\n",
    "!az storage container create \\\n",
    "    --name documents \\\n",
    "    --account-name $STORAGE_NAME \\\n",
    "    --auth-mode login\n",
    "\n",
    "print(f\"âœ… Container 'documents' ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31834fb2",
   "metadata": {},
   "source": [
    "## Managed Identity í™œì„±í™”\n",
    "\n",
    "AI Searchê°€ Storageì™€ Foundryì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ Managed Identityë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Searchì˜ Managed Identity í™œì„±í™”\n",
    "!az search service update \\\n",
    "    --name $SEARCH_NAME \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --identity-type SystemAssigned\n",
    "\n",
    "print(f\"\\nâœ… AI Search Managed Identity í™œì„±í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bce0b1",
   "metadata": {},
   "source": [
    "## IAM ê¶Œí•œ ì„¤ì •\n",
    "\n",
    "Storage Accountì™€ AI Search, Foundry ê°„ì˜ ê¶Œí•œì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c2504",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ì ë° ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71047daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì Object ID\n",
    "result = subprocess.run([\"az\", \"ad\", \"signed-in-user\", \"show\", \"--query\", \"id\", \"-o\", \"tsv\"], \n",
    "                       capture_output=True, text=True)\n",
    "USER_OBJECT_ID = result.stdout.strip()\n",
    "print(f\"ğŸ“Œ í˜„ì¬ ì‚¬ìš©ì Object ID: {USER_OBJECT_ID}\")\n",
    "\n",
    "# AI Searchì˜ Principal ID ê°€ì ¸ì˜¤ê¸°\n",
    "result = subprocess.run([\n",
    "    \"az\", \"search\", \"service\", \"show\",\n",
    "    \"--name\", SEARCH_NAME,\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--query\", \"identity.principalId\", \"-o\", \"tsv\"\n",
    "], capture_output=True, text=True)\n",
    "SEARCH_PRINCIPAL_ID = result.stdout.strip()\n",
    "print(f\"ğŸ“Œ AI Search Principal ID: {SEARCH_PRINCIPAL_ID}\")\n",
    "\n",
    "# Storage Account Resource ID ê°€ì ¸ì˜¤ê¸°\n",
    "result = subprocess.run([\n",
    "    \"az\", \"storage\", \"account\", \"show\",\n",
    "    \"--name\", STORAGE_NAME,\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--query\", \"id\", \"-o\", \"tsv\"\n",
    "], capture_output=True, text=True)\n",
    "STORAGE_RESOURCE_ID = result.stdout.strip()\n",
    "print(f\"ğŸ“Œ Storage Resource ID: {STORAGE_RESOURCE_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b4417",
   "metadata": {},
   "source": [
    "### Storage Blob Data Contributor ì—­í•  í• ë‹¹ (ì‚¬ìš©ì & AI Search MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0761b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Storage Blob Data Contributor - í˜„ì¬ ì‚¬ìš©ì\n",
    "print(\"1ï¸âƒ£ Storage Blob Data Contributor ì—­í•  í• ë‹¹ (í˜„ì¬ ì‚¬ìš©ì)...\")\n",
    "!az role assignment create \\\n",
    "    --role \"Storage Blob Data Contributor\" \\\n",
    "    --assignee $USER_OBJECT_ID \\\n",
    "    --scope $STORAGE_RESOURCE_ID\n",
    "\n",
    "# 2. Storage Blob Data Contributor - AI Search (Managed Identity)\n",
    "print(\"\\n2ï¸âƒ£ Storage Blob Data Contributor ì—­í•  í• ë‹¹ (AI Search)...\")\n",
    "!az role assignment create \\\n",
    "    --role \"Storage Blob Data Contributor\" \\\n",
    "    --assignee $SEARCH_PRINCIPAL_ID \\\n",
    "    --scope $STORAGE_RESOURCE_ID\n",
    "\n",
    "print(\"\\nâœ… Storage IAM ê¶Œí•œ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a807fb",
   "metadata": {},
   "source": [
    "### Azure AI Project Manager ì—­í•  í• ë‹¹ (AI Search MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0eaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Foundry ë¦¬ì†ŒìŠ¤ì— Azure AI Project Manager ì—­í•  í• ë‹¹ (AI Search MI)\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Foundry Resource ID ê°€ì ¸ì˜¤ê¸°\n",
    "result = subprocess.run([\n",
    "    \"az\", \"cognitiveservices\", \"account\", \"show\",\n",
    "    \"--name\", FOUNDRY_NAME,\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--query\", \"id\", \"-o\", \"tsv\"\n",
    "], capture_output=True, text=True)\n",
    "FOUNDRY_RESOURCE_ID = result.stdout.strip()\n",
    "\n",
    "print(\"3ï¸âƒ£ Azure AI Project Manager ì—­í•  í• ë‹¹ (AI Search â†’ Foundry)...\")\n",
    "!az role assignment create \\\n",
    "    --role \"Azure AI Project Manager\" \\\n",
    "    --assignee $SEARCH_PRINCIPAL_ID \\\n",
    "    --scope $FOUNDRY_RESOURCE_ID\n",
    "\n",
    "print(\"\\nâœ… Foundry IAM ê¶Œí•œ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0fa13",
   "metadata": {},
   "source": [
    "## ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œ\n",
    "\n",
    "Microsoftì—ì„œ ì œê³µí•˜ëŠ” ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ Storage Containerì— ì—…ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° URL (Azure Search Sample Data)\n",
    "sample_files = [\n",
    "    (\"Benefit_Options.pdf\", \"https://github.com/Azure-Samples/azure-search-sample-data/raw/main/health-plan/Benefit_Options.pdf\"),\n",
    "    (\"employee_handbook.pdf\", \"https://github.com/Azure-Samples/azure-search-sample-data/raw/main/health-plan/employee_handbook.pdf\"),\n",
    "    (\"Northwind_Health_Plus_Benefits_Details.pdf\", \"https://github.com/Azure-Samples/azure-search-sample-data/raw/main/health-plan/Northwind_Health_Plus_Benefits_Details.pdf\"),\n",
    "    (\"Northwind_Standard_Benefits_Details.pdf\", \"https://github.com/Azure-Samples/azure-search-sample-data/raw/main/health-plan/Northwind_Standard_Benefits_Details.pdf\"),\n",
    "    (\"PerksPlus.pdf\", \"https://github.com/Azure-Samples/azure-search-sample-data/raw/main/health-plan/PerksPlus.pdf\"),\n",
    "    (\"role_library.pdf\", \"https://github.com/Azure-Samples/azure-search-sample-data/raw/main/health-plan/role_library.pdf\"),\n",
    "]\n",
    "\n",
    "# ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(\"temp_data\", exist_ok=True)\n",
    "\n",
    "# íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "print(\"ğŸ“¥ ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "for filename, url in sample_files:\n",
    "    filepath = f\"temp_data/{filename}\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"  ë‹¤ìš´ë¡œë“œ: {filename}\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    else:\n",
    "        print(f\"  ì´ë¯¸ ì¡´ì¬: {filename}\")\n",
    "\n",
    "print(\"\\nâœ… ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d02d9",
   "metadata": {},
   "source": [
    "### Storageì— ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffcd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage Containerì— íŒŒì¼ ì—…ë¡œë“œ\n",
    "print(\"ğŸ“¤ Storage Containerì— ì—…ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "for filename, _ in sample_files:\n",
    "    filepath = f\"temp_data/{filename}\"\n",
    "    print(f\"  ì—…ë¡œë“œ: {filename}\")\n",
    "    !az storage blob upload \\\n",
    "        --account-name $STORAGE_NAME \\\n",
    "        --container-name documents \\\n",
    "        --file $filepath \\\n",
    "        --name $filename \\\n",
    "        --auth-mode login \\\n",
    "        --overwrite\n",
    "\n",
    "# ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸\n",
    "print(\"\\nğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡:\")\n",
    "!az storage blob list \\\n",
    "    --account-name $STORAGE_NAME \\\n",
    "    --container-name documents \\\n",
    "    --auth-mode login \\\n",
    "    --query \"[].name\" \\\n",
    "    --output table\n",
    "\n",
    "print(\"\\nâœ… ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "# import shutil\n",
    "# shutil.rmtree(\"temp_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde5745",
   "metadata": {},
   "source": [
    "## AI Search Index ìƒì„± (Portalì—ì„œ ì§„í–‰)\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”**: ë‹¤ìŒ ë‹¨ê³„ëŠ” Azure Portalì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Import Data Wizard ì‚¬ìš© ë°©ë²•:\n",
    "\n",
    "1. **Azure Portalì—ì„œ AI Search ë¦¬ì†ŒìŠ¤ ì—´ê¸°**\n",
    "   - https://portal.azure.com\n",
    "   - ìƒì„±í•œ AI Search ì„œë¹„ìŠ¤ ì„ íƒ\n",
    "\n",
    "2. **Import data (new) í´ë¦­**\n",
    "   \n",
    "3. **Data Source ì„¤ì •:**\n",
    "   - Data Source: **Azure Blob Storage**\n",
    "   - Scenario: **RAG (Retrieval Augmented Generation)**\n",
    "   - Storage account: `foundry<your-name>`\n",
    "   - Container: `documents`\n",
    "\n",
    "4. **Vectorization ì„¤ì •:**\n",
    "   - Kind: **Microsoft Foundry**\n",
    "   - Foundry project: `proj-default`\n",
    "   - Model deployment: **text-embedding-3-large**\n",
    "   - Authentication type: **API key**\n",
    "\n",
    "5. **Semantic Ranker í™œì„±í™”:**\n",
    "   - â˜‘ Enable semantic ranker\n",
    "   - Schedule: **Once** (ì´ˆê¸° ì¸ë±ì‹±ë§Œ)\n",
    "\n",
    "6. **Review + Create**\n",
    "   - ì„¤ì • í™•ì¸ í›„ **Create** í´ë¦­\n",
    "   - ì¸ë±ì‹± ì™„ë£Œê¹Œì§€ 5-10ë¶„ ì†Œìš”\n",
    "\n",
    "ì™„ë£Œ í›„ ì•„ë˜ ì½”ë“œë¡œ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7984f",
   "metadata": {},
   "source": [
    "## Python SDKë¡œ AI Search Index ìƒì„±\n",
    "\n",
    "Azure Search Python SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë‘ ê°€ì§€ ì˜µì…˜:**\n",
    "1. **ì˜µì…˜ A (ê¶Œì¥)**: í¬í„¸ì˜ Import Data Wizard ì‚¬ìš© - ìë™ìœ¼ë¡œ ë°ì´í„° ì¸ë±ì‹±\n",
    "2. **ì˜µì…˜ B**: ì•„ë˜ Python ì½”ë“œ ì‚¬ìš© - ì¸ë±ìŠ¤ë§Œ ìƒì„± (ë°ì´í„°ëŠ” ë³„ë„ ì—…ë¡œë“œ í•„ìš”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24e30d",
   "metadata": {},
   "source": [
    "### Azure Search SDK ì„¤ì¹˜ ë° Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install -q azure-search-documents azure-identity\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, \n",
    "    SearchField, \n",
    "    SearchFieldDataType,\n",
    "    VectorSearch, \n",
    "    VectorSearchProfile, \n",
    "    HnswAlgorithmConfiguration,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9ddaf",
   "metadata": {},
   "source": [
    "### AI Search API Key íšë“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b872f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ë°©ì‹ìœ¼ë¡œ ì¸ì¦ (RBAC ëŒ€ì•ˆ)\n",
    "# êµ¬ë… ì†Œìœ ìëŠ” API í‚¤ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "result = subprocess.run([\n",
    "    \"az\", \"search\", \"admin-key\", \"show\",\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--service-name\", SEARCH_NAME,\n",
    "    \"--query\", \"primaryKey\", \"-o\", \"tsv\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "SEARCH_API_KEY = result.stdout.strip()\n",
    "\n",
    "if SEARCH_API_KEY:\n",
    "    print(\"âœ… AI Search API í‚¤ íšë“ ì™„ë£Œ\")\n",
    "    print(\"ğŸ’¡ API í‚¤ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ RBAC ì—­í•  ì—†ì´ë„ Indexë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âš ï¸ API í‚¤ íšë“ ì‹¤íŒ¨. DefaultAzureCredential ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d78d8",
   "metadata": {},
   "source": [
    "### Search Index ìƒì„± (ë²¡í„° ê²€ìƒ‰ + Semantic Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Search Index ìƒì„±\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# ì¸ì¦ ë°©ì‹ ì„ íƒ: API í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ DefaultAzureCredential\n",
    "if 'SEARCH_API_KEY' in globals() and SEARCH_API_KEY:\n",
    "    credential = AzureKeyCredential(SEARCH_API_KEY)\n",
    "    auth_method = \"API í‚¤\"\n",
    "else:\n",
    "    credential = DefaultAzureCredential()\n",
    "    auth_method = \"DefaultAzureCredential (RBAC)\"\n",
    "\n",
    "search_endpoint = f\"https://{SEARCH_NAME}.search.windows.net\"\n",
    "\n",
    "# SearchIndexClient ìƒì„±\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Œ AI Search Endpoint: {search_endpoint}\")\n",
    "print(f\"ğŸ“Œ ìƒì„±í•  Index ì´ë¦„: {SEARCH_INDEX_NAME}\")\n",
    "print(f\"ğŸ” ì¸ì¦ ë°©ì‹: {auth_method}\")\n",
    "\n",
    "# Index í•„ë“œ ì •ì˜\n",
    "fields = [\n",
    "    # ê³ ìœ  ì‹ë³„ì\n",
    "    SearchField(\n",
    "        name=\"chunk_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        sortable=True,\n",
    "        filterable=True\n",
    "    ),\n",
    "    # ë¶€ëª¨ ë¬¸ì„œ ID\n",
    "    SearchField(\n",
    "        name=\"parent_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True\n",
    "    ),\n",
    "    # ë¬¸ì„œ ì œëª©\n",
    "    SearchField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "        sortable=True\n",
    "    ),\n",
    "    # ì²­í¬ëœ í…ìŠ¤íŠ¸ ë‚´ìš©\n",
    "    SearchField(\n",
    "        name=\"chunk\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        analyzer_name=\"ko.microsoft\"  # í•œêµ­ì–´ ë¶„ì„ê¸°\n",
    "    ),\n",
    "    # ë²¡í„° ì„ë² ë”© (text-embedding-3-large: 3072 ì°¨ì›)\n",
    "    SearchField(\n",
    "        name=\"text_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=3072,\n",
    "        vector_search_profile_name=\"my-vector-profile\"\n",
    "    ),\n",
    "    # ë©”íƒ€ë°ì´í„°\n",
    "    SearchField(\n",
    "        name=\"category\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "        facetable=True\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"sourcepage\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"sourcefile\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ë²¡í„° ê²€ìƒ‰ êµ¬ì„±\n",
    "vector_search = VectorSearch(\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"my-vector-profile\",\n",
    "            algorithm_configuration_name=\"my-hnsw-config\"\n",
    "        )\n",
    "    ],\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"my-hnsw-config\",\n",
    "            parameters={\n",
    "                \"m\": 4,  # ê·¸ë˜í”„ ì—°ê²° ìˆ˜\n",
    "                \"efConstruction\": 400,  # ì¸ë±ì‹± ì‹œ íƒìƒ‰ ë²”ìœ„\n",
    "                \"efSearch\": 500,  # ê²€ìƒ‰ ì‹œ íƒìƒ‰ ë²”ìœ„\n",
    "                \"metric\": \"cosine\"  # ìœ ì‚¬ë„ ì¸¡ì • ë°©ì‹\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Semantic Search êµ¬ì„± (ì„ íƒ ì‚¬í•­)\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        content_fields=[\n",
    "            SemanticField(field_name=\"chunk\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "semantic_search = SemanticSearch(\n",
    "    configurations=[semantic_config]\n",
    ")\n",
    "\n",
    "# Index ìƒì„±\n",
    "index = SearchIndex(\n",
    "    name=SEARCH_INDEX_NAME,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Index ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸\n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f\"\\nâœ… AI Search Index ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"   Index ì´ë¦„: {result.name}\")\n",
    "    print(f\"   í•„ë“œ ìˆ˜: {len(result.fields)}\")\n",
    "    print(f\"   ë²¡í„° ê²€ìƒ‰: í™œì„±í™” (3072 ì°¨ì›)\")\n",
    "    print(f\"   Semantic Search: í™œì„±í™”\")\n",
    "    \n",
    "    # ì„¤ì • íŒŒì¼ì— ì €ì¥\n",
    "    config[\"SEARCH_INDEX_NAME\"] = SEARCH_INDEX_NAME\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Index ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:\")\n",
    "    print(\"   1. AI Search ë¦¬ì†ŒìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ (ëª‡ ë¶„ ëŒ€ê¸°)\")\n",
    "    print(\"   2. ê¶Œí•œ ë¬¸ì œ:\")\n",
    "    print(\"      - RBAC ë°©ì‹: 'Search Index Data Contributor' ì—­í•  í•„ìš”\")\n",
    "    print(\"      - êµ¬ë… ì†Œìœ ìë„ Data Plane ê¶Œí•œì€ ë³„ë„ë¡œ í•„ìš”í•©ë‹ˆë‹¤\")\n",
    "    print(\"   3. ìœ„ì˜ API í‚¤ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ë©´ RBAC ì—†ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5829e4",
   "metadata": {},
   "source": [
    "### ìƒì„±ëœ Index ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ì„ íƒ ì‚¬í•­) ìƒì„±ëœ Index í™•ì¸\n",
    "try:\n",
    "    # ìƒì„±ëœ Index ê°€ì ¸ì˜¤ê¸°\n",
    "    created_index = index_client.get_index(SEARCH_INDEX_NAME)\n",
    "    \n",
    "    print(\"ğŸ“‹ Index ìƒì„¸ ì •ë³´:\")\n",
    "    print(f\"\\ní•„ë“œ ëª©ë¡:\")\n",
    "    for field in created_index.fields:\n",
    "        field_info = f\"  - {field.name} ({field.type})\"\n",
    "        if field.key:\n",
    "            field_info += \" [KEY]\"\n",
    "        if field.searchable:\n",
    "            field_info += \" [ê²€ìƒ‰ ê°€ëŠ¥]\"\n",
    "        if hasattr(field, 'vector_search_dimensions') and field.vector_search_dimensions:\n",
    "            field_info += f\" [ë²¡í„°: {field.vector_search_dimensions}ì°¨ì›]\"\n",
    "        print(field_info)\n",
    "    \n",
    "    print(f\"\\në²¡í„° ê²€ìƒ‰ í”„ë¡œí•„: {len(created_index.vector_search.profiles) if created_index.vector_search else 0}ê°œ\")\n",
    "    print(f\"Semantic êµ¬ì„±: {len(created_index.semantic_search.configurations) if created_index.semantic_search else 0}ê°œ\")\n",
    "    \n",
    "    # Index ëª©ë¡ í™•ì¸\n",
    "    print(\"\\nğŸ“‹ ì „ì²´ Index ëª©ë¡:\")\n",
    "    indexes = index_client.list_indexes()\n",
    "    for idx in indexes:\n",
    "        print(f\"  - {idx.name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Index ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae78b07",
   "metadata": {},
   "source": [
    "## ë¬¸ì„œ ì¸ë±ì‹± (ì§ì ‘ í‘¸ì‹œ ë°©ì‹)\n",
    "\n",
    "Storageì˜ PDF ë¬¸ì„œë¥¼ ì½ì–´ì„œ ì§ì ‘ Indexì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "- PDF íŒŒì‹± ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "- í…ìŠ¤íŠ¸ ì²­í‚¹ (2000ì ë‹¨ìœ„)\n",
    "- Foundry APIë¡œ ì„ë² ë”© ìƒì„±\n",
    "- AI Search Indexì— ë¬¸ì„œ ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eef549",
   "metadata": {},
   "source": [
    "### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10758275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install -q pypdf azure-storage-blob openai\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.search.documents import SearchClient\n",
    "from pypdf import PdfReader\n",
    "from openai import AzureOpenAI\n",
    "import io\n",
    "import hashlib\n",
    "import base64\n",
    "\n",
    "print(\"âœ… í•„ìš”í•œ íŒ¨í‚¤ì§€ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d5f1f",
   "metadata": {},
   "source": [
    "### Storageì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storageì—ì„œ PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Blob Service Client ìƒì„±\n",
    "storage_credential = DefaultAzureCredential()\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{STORAGE_NAME}.blob.core.windows.net\",\n",
    "    credential=storage_credential\n",
    ")\n",
    "\n",
    "container_client = blob_service_client.get_container_client(\"documents\")\n",
    "\n",
    "# ì»¨í…Œì´ë„ˆì˜ ëª¨ë“  PDF íŒŒì¼ ë‚˜ì—´\n",
    "print(\"ğŸ“¥ Storageì—ì„œ PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...\\n\")\n",
    "pdf_files = []\n",
    "\n",
    "for blob in container_client.list_blobs():\n",
    "    if blob.name.endswith('.pdf'):\n",
    "        print(f\"  ë‹¤ìš´ë¡œë“œ: {blob.name}\")\n",
    "        blob_client = container_client.get_blob_client(blob.name)\n",
    "        pdf_data = blob_client.download_blob().readall()\n",
    "        pdf_files.append({\n",
    "            'name': blob.name,\n",
    "            'data': pdf_data\n",
    "        })\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(pdf_files)}ê°œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4a84d",
   "metadata": {},
   "source": [
    "### PDF í…ìŠ¤íŠ¸ ì²­í‚¹ ë° ë©”íƒ€ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF íŒŒì‹± ë° í…ìŠ¤íŠ¸ ì²­í‚¹\n",
    "def chunk_text(text, chunk_size=2000, overlap=200):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ì²­í‚¹\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    \n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # ì˜¤ë²„ë© ì ìš©\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "print(\"ğŸ“„ PDF íŒŒì‹± ë° í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...\\n\")\n",
    "all_chunks = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        # PDF ì½ê¸°\n",
    "        pdf_reader = PdfReader(io.BytesIO(pdf_file['data']))\n",
    "        \n",
    "        # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        full_text = \"\"\n",
    "        for page_num, page in enumerate(pdf_reader.pages, 1):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                full_text += text + \"\\n\"\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ì²­í‚¹\n",
    "        chunks = chunk_text(full_text)\n",
    "        \n",
    "        # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥\n",
    "        for chunk_idx, chunk_content in enumerate(chunks):\n",
    "            chunk_id = hashlib.md5(f\"{pdf_file['name']}_{chunk_idx}\".encode()).hexdigest()\n",
    "            \n",
    "            all_chunks.append({\n",
    "                'chunk_id': chunk_id,\n",
    "                'parent_id': pdf_file['name'],\n",
    "                'title': pdf_file['name'].replace('.pdf', ''),\n",
    "                'chunk': chunk_content.strip(),\n",
    "                'sourcefile': pdf_file['name'],\n",
    "                'sourcepage': f\"page_{chunk_idx + 1}\",\n",
    "                'category': 'health-plan'\n",
    "            })\n",
    "        \n",
    "        print(f\"  âœ“ {pdf_file['name']}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ {pdf_file['name']} íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4fcbc",
   "metadata": {},
   "source": [
    "### Azure OpenAIë¡œ ì„ë² ë”© ìƒì„± ë° Indexì— ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI REST APIë¡œ ì„ë² ë”© ìƒì„±\n",
    "print(\"ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...\\n\")\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "api_version = \"2024-02-01\"\n",
    "\n",
    "# Azure OpenAI ì—”ë“œí¬ì¸íŠ¸ ì°¾ê¸°\n",
    "print(\"ğŸ” ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ì—ì„œ Azure OpenAI ê³„ì • ì°¾ëŠ” ì¤‘...\")\n",
    "\n",
    "# Azure CLIë¡œ ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ì˜ Cognitive Services ê³„ì • ì°¾ê¸°\n",
    "result = subprocess.run([\n",
    "    \"az\", \"cognitiveservices\", \"account\", \"list\",\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--query\", \"[?kind=='OpenAI'].{name:name, endpoint:properties.endpoint}\",\n",
    "    \"-o\", \"json\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "openai_accounts = json.loads(result.stdout) if result.stdout else []\n",
    "print(f\"ğŸ“‹ ë°œê²¬ëœ OpenAI ê³„ì •: {len(openai_accounts)}ê°œ\")\n",
    "\n",
    "if openai_accounts:\n",
    "    # ì²« ë²ˆì§¸ Azure OpenAI ê³„ì • ì‚¬ìš©\n",
    "    openai_account = openai_accounts[0]\n",
    "    openai_name = openai_account['name']\n",
    "    openai_endpoint = openai_account['endpoint']\n",
    "    \n",
    "    print(f\"âœ… Azure OpenAI ê³„ì •: {openai_name}\")\n",
    "    print(f\"ğŸ”— Endpoint: {openai_endpoint}\")\n",
    "    \n",
    "    # ë°°í¬ëœ ëª¨ë¸ í™•ì¸\n",
    "    result = subprocess.run([\n",
    "        \"az\", \"cognitiveservices\", \"account\", \"deployment\", \"list\",\n",
    "        \"--name\", openai_name,\n",
    "        \"--resource-group\", RESOURCE_GROUP,\n",
    "        \"--query\", \"[].{name:name, model:properties.model.name}\",\n",
    "        \"-o\", \"json\"\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    deployments = json.loads(result.stdout) if result.stdout else []\n",
    "    print(f\"\\nğŸ“¦ ë°°í¬ëœ ëª¨ë¸:\")\n",
    "    for dep in deployments:\n",
    "        print(f\"   - {dep['name']}: {dep['model']}\")\n",
    "    \n",
    "    # embedding ëª¨ë¸ ì°¾ê¸°\n",
    "    embedding_deployment = None\n",
    "    for dep in deployments:\n",
    "        if \"embedding\" in dep['name'].lower() or \"embedding\" in dep['model'].lower():\n",
    "            embedding_deployment = dep['name']\n",
    "            print(f\"\\nâœ… ì„ë² ë”© ëª¨ë¸ ë°°í¬ ë°œê²¬: {embedding_deployment}\")\n",
    "            break\n",
    "    \n",
    "    if not embedding_deployment:\n",
    "        # ê¸°ë³¸ ì´ë¦„ìœ¼ë¡œ ì‹œë„\n",
    "        embedding_deployment = embedding_model\n",
    "        print(f\"\\nğŸ’¡ ê¸°ë³¸ ë°°í¬ ì´ë¦„ ì‚¬ìš©: {embedding_deployment}\")\n",
    "    \n",
    "    # REST API URL êµ¬ì„±\n",
    "    embeddings_url = f\"{openai_endpoint.rstrip('/')}/openai/deployments/{embedding_deployment}/embeddings?api-version={api_version}\"\n",
    "    token_scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Azure OpenAI ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ Foundry ë¦¬ì†ŒìŠ¤ ìì²´ë¥¼ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # Foundry ë¦¬ì†ŒìŠ¤ì˜ ì—”ë“œí¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    result = subprocess.run([\n",
    "        \"az\", \"cognitiveservices\", \"account\", \"show\",\n",
    "        \"--name\", FOUNDRY_NAME,\n",
    "        \"--resource-group\", RESOURCE_GROUP,\n",
    "        \"--query\", \"properties.endpoint\",\n",
    "        \"-o\", \"tsv\"\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    foundry_endpoint = result.stdout.strip()\n",
    "    print(f\"ğŸ”— Foundry Endpoint: {foundry_endpoint}\")\n",
    "    \n",
    "    embeddings_url = f\"{foundry_endpoint.rstrip('/')}/openai/deployments/{embedding_model}/embeddings?api-version={api_version}\"\n",
    "    token_scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "\n",
    "print(f\"\\nğŸ“ ì„ë² ë”© API URL: {embeddings_url}\")\n",
    "print(f\"ğŸ” ì¸ì¦ Scope: {token_scope}\")\n",
    "\n",
    "# Azure ì¸ì¦ í† í° ê°€ì ¸ì˜¤ê¸°\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (Rate limit ì•ˆì •ì  ì²˜ë¦¬)\n",
    "batch_size = 30  # Rate limit ê³ ë ¤í•˜ì—¬ ì‘ì€ ë°°ì¹˜\n",
    "embedded_chunks = []\n",
    "max_retries = 5\n",
    "base_retry_delay = 30  # ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„ 30ì´ˆ\n",
    "\n",
    "print(f\"\\nâš¡ ì„ë² ë”© ìƒì„± ì‹œì‘ (ì´ {len(all_chunks)}ê°œ, ë°°ì¹˜ë‹¹ {batch_size}ê°œ)\")\n",
    "print(f\"ğŸ’¡ ì•ˆì •ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ Rate limit ë°œìƒ ì‹œ ëŒ€ê¸°í•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "for i in range(0, len(all_chunks), batch_size):\n",
    "    batch = all_chunks[i:i+batch_size]\n",
    "    batch_texts = [chunk['chunk'] for chunk in batch]\n",
    "    batch_num = i // batch_size + 1\n",
    "    total_batches = (len(all_chunks) + batch_size - 1) // batch_size\n",
    "    \n",
    "    success = False\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            # ì•¡ì„¸ìŠ¤ í† í° ê°€ì ¸ì˜¤ê¸°\n",
    "            token = credential.get_token(token_scope)\n",
    "            \n",
    "            # REST API í˜¸ì¶œ\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {token.token}\"\n",
    "            }\n",
    "            \n",
    "            payload = {\n",
    "                \"input\": batch_texts,\n",
    "                \"dimensions\": 3072\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                embeddings_url,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                \n",
    "                # ì„ë² ë”©ì„ ì²­í¬ì— ì¶”ê°€\n",
    "                for j, chunk in enumerate(batch):\n",
    "                    chunk['text_vector'] = result['data'][j]['embedding']\n",
    "                    embedded_chunks.append(chunk)\n",
    "                \n",
    "                print(f\"  âœ… ë°°ì¹˜ {batch_num}/{total_batches}: {len(embedded_chunks)}/{len(all_chunks)} ì²­í¬ ì™„ë£Œ\")\n",
    "                success = True\n",
    "                break\n",
    "                \n",
    "            elif response.status_code == 429:\n",
    "                # Rate limit ì˜¤ë¥˜ - ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì¬ì‹œë„\n",
    "                if retry < max_retries - 1:\n",
    "                    wait_time = base_retry_delay * (2 ** retry)  # 30, 60, 120, 240ì´ˆ...\n",
    "                    print(f\"  â³ ë°°ì¹˜ {batch_num}/{total_batches}: Rate limit. {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({retry+1}/{max_retries})...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"  âš ï¸ ë°°ì¹˜ {batch_num}/{total_batches}: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ - ìŠ¤í‚µ\")\n",
    "                    for chunk in batch:\n",
    "                        chunk['text_vector'] = None\n",
    "                        embedded_chunks.append(chunk)\n",
    "                    success = True  # ë‹¤ìŒ ë°°ì¹˜ë¡œ ì§„í–‰\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"  âš ï¸ ë°°ì¹˜ {batch_num}/{total_batches} ì‹¤íŒ¨ (HTTP {response.status_code}): {response.text[:150]}\")\n",
    "                for chunk in batch:\n",
    "                    chunk['text_vector'] = None\n",
    "                    embedded_chunks.append(chunk)\n",
    "                success = True  # ë‹¤ìŒ ë°°ì¹˜ë¡œ ì§„í–‰\n",
    "                break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ ë°°ì¹˜ {batch_num}/{total_batches} ì˜¤ë¥˜: {str(e)[:100]}\")\n",
    "            if retry < max_retries - 1:\n",
    "                print(f\"     ì¬ì‹œë„ {retry + 1}/{max_retries}...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                for chunk in batch:\n",
    "                    chunk['text_vector'] = None\n",
    "                    embedded_chunks.append(chunk)\n",
    "                success = True\n",
    "                break\n",
    "    \n",
    "    # ë°°ì¹˜ ê°„ 1ì´ˆ ëŒ€ê¸° (Rate limit ë°©ì§€)\n",
    "    if i + batch_size < len(all_chunks) and success:\n",
    "        time.sleep(1)\n",
    "\n",
    "print(f\"\\nâœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embedded_chunks)}ê°œ ì²­í¬\")\n",
    "print(f\"ğŸ“Š ë²¡í„° ì°¨ì›: {len(embedded_chunks[0]['text_vector']) if embedded_chunks and embedded_chunks[0].get('text_vector') else 0}ì°¨ì›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43467986",
   "metadata": {},
   "source": [
    "### Foundry MIì— Search Index Data Reader ì—­í•  í• ë‹¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695dc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexì— ë¬¸ì„œ ì—…ë¡œë“œ\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# API í‚¤ë¡œ SearchClient ìƒì„± (RBAC ëŒ€ì‹  API í‚¤ ì‚¬ìš©)\n",
    "upload_credential = AzureKeyCredential(SEARCH_API_KEY) if SEARCH_API_KEY else DefaultAzureCredential()\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=SEARCH_INDEX_NAME,\n",
    "    credential=upload_credential\n",
    ")\n",
    "\n",
    "print(\"ğŸ“¤ Indexì— ë¬¸ì„œ ì—…ë¡œë“œ ì¤‘...\")\n",
    "print(f\"ğŸ” ì¸ì¦ ë°©ì‹: {'API í‚¤' if SEARCH_API_KEY else 'DefaultAzureCredential'}\\n\")\n",
    "\n",
    "# ë°°ì¹˜ ì—…ë¡œë“œ (ìµœëŒ€ 1000ê°œì”©)\n",
    "batch_size = 30\n",
    "uploaded_count = 0\n",
    "\n",
    "for i in range(0, len(embedded_chunks), batch_size):\n",
    "    batch = embedded_chunks[i:i+batch_size]\n",
    "    \n",
    "    # None ë²¡í„° ì œê±° (ì„ë² ë”© ì‹¤íŒ¨í•œ ê²½ìš°)\n",
    "    valid_batch = [chunk for chunk in batch if chunk['text_vector'] is not None]\n",
    "    \n",
    "    if not valid_batch:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # ë¬¸ì„œ ì—…ë¡œë“œ\n",
    "        result = search_client.upload_documents(documents=valid_batch)\n",
    "        \n",
    "        # ì„±ê³µí•œ ë¬¸ì„œ ìˆ˜ ì¹´ìš´íŠ¸\n",
    "        succeeded = sum(1 for r in result if r.succeeded)\n",
    "        uploaded_count += succeeded\n",
    "        \n",
    "        print(f\"  ì—…ë¡œë“œ: {uploaded_count}/{len([c for c in embedded_chunks if c['text_vector']])} ì²­í¬\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ë°°ì¹˜ {i//batch_size + 1} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… ì¸ë±ì‹± ì™„ë£Œ!\")\n",
    "print(f\"   ì´ ì—…ë¡œë“œ: {uploaded_count}ê°œ ë¬¸ì„œ\")\n",
    "print(f\"   Index: {SEARCH_INDEX_NAME}\")\n",
    "print(f\"\\nğŸ’¡ Index í™•ì¸:\")\n",
    "print(f\"   https://portal.azure.com â†’ {SEARCH_NAME} â†’ Indexes â†’ {SEARCH_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d80c16",
   "metadata": {},
   "source": [
    "### Foundryì— AI Search Connection ìƒì„± (REST API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a606a",
   "metadata": {},
   "source": [
    "## Knowledge Base ìƒì„± (ì½”ë“œ ê¸°ë°˜)\n",
    "\n",
    "**ì¤‘ìš”**: Knowledge Base APIëŠ” í”„ë¦¬ë·° ê¸°ëŠ¥ìœ¼ë¡œ, í”„ë¦¬ë·° ë²„ì „ SDKê°€ í•„ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff487a1",
   "metadata": {},
   "source": [
    "### Azure Search Documents í”„ë¦¬ë·° ë²„ì „ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base API ì§€ì›ì„ ìœ„í•œ í”„ë¦¬ë·° ë²„ì „ ì„¤ì¹˜\n",
    "print(\"ğŸ“¦ í”„ë¦¬ë·° SDK ì„¤ì¹˜ ì¤‘...\")\n",
    "%pip install -q --upgrade azure-search-documents==11.7.0b2\n",
    "\n",
    "print(\"\\nâœ… azure-search-documents 11.7.0b2 ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "print(\"   (Knowledge Base API ì§€ì›)\")\n",
    "\n",
    "print(\"\\nâš ï¸  ì¤‘ìš”: ì»¤ë„ ì¬ì‹œì‘ í•„ìš”!\")\n",
    "print(\"   1. ìƒë‹¨ ë©”ë‰´: Kernel > Restart Kernel\")\n",
    "print(\"   2. ë˜ëŠ” ì•„ë˜ ì…€ ì‹¤í–‰í•˜ì—¬ ìë™ ì¬ì‹œì‘\")\n",
    "print(\"\\nğŸ’¡ ì»¤ë„ ì¬ì‹œì‘ í›„ ë‹¤ìŒ ì…€ë¶€í„° ê³„ì† ì§„í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186108e3",
   "metadata": {},
   "source": [
    "## Foundry Managed Identityì— AI Search ê¶Œí•œ ë¶€ì—¬ (**í•„ìˆ˜**)\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”**: API Key Connectionë§Œìœ¼ë¡œëŠ” **Agent ì‹¤í–‰ì´ ë¶ˆê°€ëŠ¥**í•©ë‹ˆë‹¤!\n",
    "\n",
    "**ê¶Œí•œ êµ¬ì¡°:**\n",
    "- ğŸ”‘ **API Key Connection** â†’ í¬í„¸ì—ì„œ Knowledge Base ì¡°íšŒìš© (Cell 60)\n",
    "- ğŸ¤– **Managed Identity ê¶Œí•œ** â†’ Agentê°€ Knowledge Base ì‹¤í–‰ìš© (**ì´ ì„¹ì…˜**)\n",
    "\n",
    "**ì™œ í•„ìš”í•œê°€?**\n",
    "- Agent ì‹¤í–‰ ì‹œ Foundryì˜ Managed Identityë¡œ Knowledge Base MCP ì—”ë“œí¬ì¸íŠ¸ì— ì ‘ê·¼\n",
    "- API KeyëŠ” Connection ì„¤ì •ìš©ì´ë©°, Agent ëŸ°íƒ€ì„ì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ\n",
    "- 403 Forbidden ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë°˜ë“œì‹œ ì„¤ì • í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foundry Managed Identityì— AI Search ê¶Œí•œ ë¶€ì—¬ (Agent ì‹¤í–‰ìš© - í•„ìˆ˜!)\n",
    "print(\"ğŸ” Foundry Managed Identityì— AI Search ê¶Œí•œ ì„¤ì • ì¤‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "import requests\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.authorization import AuthorizationManagementClient\n",
    "from azure.mgmt.authorization.models import RoleAssignmentCreateParameters\n",
    "\n",
    "try:\n",
    "    # config íŒŒì¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ë¡œë“œ\n",
    "    config_file = '.foundry_config.json'\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    FOUNDRY_NAME = config.get(\"FOUNDRY_NAME\")\n",
    "    RESOURCE_GROUP = config.get(\"RESOURCE_GROUP\")\n",
    "    SEARCH_NAME = config.get(\"SEARCH_NAME\")\n",
    "    SUBSCRIPTION_ID = config.get(\"AZURE_SUBSCRIPTION_ID\") or config.get(\"SUBSCRIPTION_ID\")\n",
    "    \n",
    "    # Foundry ë¦¬ì†ŒìŠ¤ ID\n",
    "    foundry_account_id = f\"/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.CognitiveServices/accounts/{FOUNDRY_NAME}\"\n",
    "    \n",
    "    # AI Search ë¦¬ì†ŒìŠ¤ ID\n",
    "    search_resource_id = f\"/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.Search/searchServices/{SEARCH_NAME}\"\n",
    "    \n",
    "    credential = DefaultAzureCredential()\n",
    "    \n",
    "    # Foundryì˜ Managed Identity Principal ID ê°€ì ¸ì˜¤ê¸°\n",
    "    print(f\"\\nğŸ” Foundry Managed Identity í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token.token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    foundry_url = f\"https://management.azure.com{foundry_account_id}?api-version=2025-09-01\"\n",
    "    response = requests.get(foundry_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Foundry ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}\")\n",
    "    \n",
    "    foundry_data = response.json()\n",
    "    principal_id = foundry_data.get(\"identity\", {}).get(\"principalId\")\n",
    "    \n",
    "    if not principal_id:\n",
    "        print(f\"   âš ï¸ Foundryì˜ Managed Identityê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"   ğŸ’¡ Managed Identity í™œì„±í™” ì¤‘...\")\n",
    "        \n",
    "        # Managed Identity í™œì„±í™”\n",
    "        foundry_data[\"identity\"] = {\"type\": \"SystemAssigned\"}\n",
    "        update_response = requests.patch(foundry_url, headers=headers, json={\"identity\": {\"type\": \"SystemAssigned\"}})\n",
    "        \n",
    "        if update_response.status_code in [200, 201]:\n",
    "            principal_id = update_response.json().get(\"identity\", {}).get(\"principalId\")\n",
    "            print(f\"   âœ… Managed Identity í™œì„±í™” ì™„ë£Œ!\")\n",
    "        else:\n",
    "            raise Exception(f\"Managed Identity í™œì„±í™” ì‹¤íŒ¨: {update_response.text}\")\n",
    "    \n",
    "    print(f\"   âœ… Principal ID: {principal_id}\")\n",
    "    \n",
    "    # Role Assignment ìƒì„±\n",
    "    auth_client = AuthorizationManagementClient(credential, SUBSCRIPTION_ID)\n",
    "    \n",
    "    # í•„ìš”í•œ ì—­í•  ì •ì˜ (Agent ì‹¤í–‰ìš©)\n",
    "    roles_to_assign = [\n",
    "        {\n",
    "            \"name\": \"Search Index Data Reader\",\n",
    "            \"id\": \"1407120a-92aa-4202-b7e9-c0e197c71c8f\",\n",
    "            \"purpose\": \"Knowledge Base ë°ì´í„° ì½ê¸°\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Search Service Contributor\",\n",
    "            \"id\": \"7ca78c08-252a-4471-8644-bb5ff32d4ba0\",\n",
    "            \"purpose\": \"Knowledge Base MCP ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for role in roles_to_assign:\n",
    "        print(f\"\\nğŸš€ '{role['name']}' ê¶Œí•œ í™•ì¸ ì¤‘...\")\n",
    "        print(f\"   ëª©ì : {role['purpose']}\")\n",
    "        \n",
    "        role_definition_id = f\"/subscriptions/{SUBSCRIPTION_ID}/providers/Microsoft.Authorization/roleDefinitions/{role['id']}\"\n",
    "        \n",
    "        # ê¸°ì¡´ role assignment í™•ì¸\n",
    "        existing_assignments = list(auth_client.role_assignments.list_for_scope(\n",
    "            scope=search_resource_id,\n",
    "            filter=f\"principalId eq '{principal_id}'\"\n",
    "        ))\n",
    "        \n",
    "        has_role = any(\n",
    "            role['id'] in assignment.role_definition_id\n",
    "            for assignment in existing_assignments\n",
    "        )\n",
    "        \n",
    "        if has_role:\n",
    "            print(f\"   âœ… '{role['name']}' ê¶Œí•œì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            # ìƒˆ Role Assignment ìƒì„±\n",
    "            role_assignment_name = str(uuid.uuid4())\n",
    "            role_assignment_params = RoleAssignmentCreateParameters(\n",
    "                role_definition_id=role_definition_id,\n",
    "                principal_id=principal_id,\n",
    "                principal_type=\"ServicePrincipal\"\n",
    "            )\n",
    "            \n",
    "            assignment = auth_client.role_assignments.create(\n",
    "                scope=search_resource_id,\n",
    "                role_assignment_name=role_assignment_name,\n",
    "                parameters=role_assignment_params\n",
    "            )\n",
    "            \n",
    "            print(f\"   âœ… '{role['name']}' ê¶Œí•œ ë¶€ì—¬ ì™„ë£Œ!\")\n",
    "            print(f\"   Assignment ID: {assignment.name}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… Agent ì‹¤í–‰ìš© ê¶Œí•œ ì„¤ì • ì™„ë£Œ!\")\n",
    "    print(f\"\\nâš ï¸ ì¤‘ìš”: ê¶Œí•œì´ ì „íŒŒë˜ëŠ”ë° 2-3ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ’¡ 2-3ë¶„ í›„:\")\n",
    "    print(f\"   1. Agent í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥\")\n",
    "    print(f\"   2. 403 Forbidden ì—ëŸ¬ í•´ê²°\")\n",
    "    print(f\"   3. Knowledge Base MCP ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ ì ‘ê·¼\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ ê¶Œí•œ ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7a9df",
   "metadata": {},
   "source": [
    "### Azure AI Search ì—°ê²° ì¶”ê°€\n",
    "\n",
    "Foundry IQì—ì„œ Knowledge Baseë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë¨¼ì € AI Search ë¦¬ì†ŒìŠ¤ë¥¼ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**Foundry IQì—ì„œ AI Search ì—°ê²°í•˜ê¸°:**\n",
    "\n",
    "1. **Azure AI Foundry Portal ì ‘ì†**\n",
    "   - https://ai.azure.com ì ‘ì†\n",
    "   - ìƒì„±í•œ Foundry í”„ë¡œì íŠ¸ ì„ íƒ\n",
    "\n",
    "2. **Foundry IQ ë©”ë‰´ë¡œ ì´ë™**\n",
    "   - ì™¼ìª½ ë©”ë‰´ì—ì„œ **Foundry IQ** í´ë¦­\n",
    "   - \"Ground your agent in enterprise knowledge\" í™”ë©´ì´ í‘œì‹œë¨\n",
    "\n",
    "3. **AI Search ë¦¬ì†ŒìŠ¤ ì—°ê²°**\n",
    "   - **Azure AI Search resource** ë“œë¡­ë‹¤ìš´ í´ë¦­\n",
    "   - ìƒì„±í•œ AI Search ì„œë¹„ìŠ¤ ì„ íƒ\n",
    "   - **Connect** ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "4. **ì—°ê²° ì™„ë£Œ**\n",
    "   - AI Search ë¦¬ì†ŒìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ë©´ Knowledge basesì™€ Indexes íƒ­ì´ í™œì„±í™”ë©ë‹ˆë‹¤\n",
    "\n",
    "> **ğŸ’¡ Tip**: \n",
    "> - AI Search ë¦¬ì†ŒìŠ¤ê°€ ëª©ë¡ì— ì—†ë‹¤ë©´ \"Create new resource\" ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ìƒˆë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "> - ì—°ê²° í›„ì—ëŠ” ì½”ë“œì—ì„œ `project_client.connections.list()`ë¡œ ì—°ê²°ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e44141",
   "metadata": {},
   "source": [
    "## Knowledge Base ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Baseë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import json\n",
    "import subprocess\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes.models import (\n",
    "    KnowledgeBase,\n",
    "    KnowledgeSourceReference,\n",
    "    KnowledgeBaseAzureOpenAIModel,\n",
    "    SearchIndexKnowledgeSource,\n",
    "    SearchIndexKnowledgeSourceParameters,\n",
    "    SearchIndexFieldReference,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    KnowledgeRetrievalOutputMode\n",
    ")\n",
    "\n",
    "# config íŒŒì¼ ë¡œë“œ\n",
    "config_file = '.foundry_config.json'\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "SEARCH_NAME = config.get(\"SEARCH_NAME\")\n",
    "\n",
    "# AI Search API í‚¤ íšë“ (ëª…ë ¹ì–´ë¡œ ì¡°íšŒ)\n",
    "result = subprocess.run([\n",
    "    \"az\", \"search\", \"admin-key\", \"show\",\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--service-name\", SEARCH_NAME,\n",
    "    \"--query\", \"primaryKey\", \"-o\", \"tsv\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "SEARCH_API_KEY = result.stdout.strip()\n",
    "search_endpoint = f\"https://{SEARCH_NAME}.search.windows.net\"\n",
    "\n",
    "# SearchIndexClient ì´ˆê¸°í™” (API Key ì‚¬ìš©)\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=AzureKeyCredential(SEARCH_API_KEY)\n",
    ")\n",
    "\n",
    "print(\"âœ… Knowledge Base ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")\n",
    "print(f\"   - KnowledgeBase\")\n",
    "print(f\"   - KnowledgeSourceReference\")\n",
    "print(f\"   - KnowledgeBaseAzureOpenAIModel\")\n",
    "print(f\"   - SearchIndexKnowledgeSource\")\n",
    "print(f\"   - SearchIndexKnowledgeSourceParameters\")\n",
    "print(f\"   - SearchIndexFieldReference\")\n",
    "print(f\"âœ… SearchIndexClient ì´ˆê¸°í™” ì™„ë£Œ: {search_endpoint}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381811c",
   "metadata": {},
   "source": [
    "### Knowledge Source ìƒì„± (Search Index ì—°ê²°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”— 1ë‹¨ê³„: Knowledge Source ìƒì„± ì¤‘...\")\n",
    "KNOWLEDGE_SOURCE_NAME = \"knowledge-source-01\"\n",
    "\n",
    "try:\n",
    "    knowledge_source = SearchIndexKnowledgeSource(\n",
    "        name=KNOWLEDGE_SOURCE_NAME,\n",
    "        description=\"Foundry IQ Knowledge Source from existing search index\",\n",
    "        search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "            search_index_name=SEARCH_INDEX_NAME,\n",
    "            # ê²€ìƒ‰ì— ì‚¬ìš©í•  í•„ë“œë“¤ ì§€ì • (ì‹¤ì œ ì¸ë±ìŠ¤ í•„ë“œ ì´ë¦„ ì‚¬ìš©)\n",
    "            source_data_fields=[\n",
    "                SearchIndexFieldReference(name=\"chunk\"),  # í…ìŠ¤íŠ¸ ì½˜í…ì¸ \n",
    "                SearchIndexFieldReference(name=\"title\")   # ë¬¸ì„œ ì œëª©\n",
    "            ],\n",
    "            # ê²€ìƒ‰ í•„ë“œ (í‚¤ í•„ë“œ - ì‹¤ì œ ì¸ë±ìŠ¤ì˜ í‚¤ í•„ë“œ ì´ë¦„ ì‚¬ìš©)\n",
    "            search_fields=[\n",
    "                SearchIndexFieldReference(name=\"chunk_id\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result_ks = index_client.create_or_update_knowledge_source(knowledge_source)\n",
    "    print(f\"   âœ… Knowledge Source ìƒì„± ì™„ë£Œ: {KNOWLEDGE_SOURCE_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Knowledge Source ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"   ğŸ’¡ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed706c",
   "metadata": {},
   "source": [
    "### Knowledge Base ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53293b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“š 2ë‹¨ê³„: Knowledge Base ìƒì„± ì¤‘...\")\n",
    "KNOWLEDGE_BASE_NAME = \"foundry-knowledge-base\"\n",
    "\n",
    "# configì—ì„œ í•„ìš”í•œ ë³€ìˆ˜ ë¡œë“œ\n",
    "FOUNDRY_ENDPOINT = config.get(\"FOUNDRY_ENDPOINT\")\n",
    "SEARCH_INDEX_NAME = config.get(\"SEARCH_INDEX_NAME\", \"knowledge-index\")\n",
    "KNOWLEDGE_SOURCE_NAME = config.get(\"KNOWLEDGE_SOURCE_NAME\", \"knowledge-source-01\")\n",
    "\n",
    "# Azure OpenAI íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# answer synthesisë¥¼ ìœ„í•œ GPT ëª¨ë¸ ì‚¬ìš©\n",
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=FOUNDRY_ENDPOINT,  # Foundry ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©\n",
    "    deployment_name=\"gpt-4.1\",  # GPT ë°°í¬ ì´ë¦„\n",
    "    model_name=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    knowledge_base = KnowledgeBase(\n",
    "        name=KNOWLEDGE_BASE_NAME,\n",
    "        description=\"Foundry IQ Knowledge Base for HR documents\",\n",
    "        retrieval_instructions=\"ì´ ì§€ì‹ ê¸°ë°˜ì€ HR ê´€ë ¨ ë¬¸ì„œë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì§ì› ë³µë¦¬í›„ìƒ, ì±„ìš© ì •ì±… ë“±ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\",\n",
    "        answer_instructions=\"ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. ë¬¸ì„œì—ì„œ ì§ì ‘ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì´ì„¸ìš”.\",\n",
    "        output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,  # ìë™ ë‹µë³€ í•©ì„±\n",
    "        knowledge_sources=[\n",
    "            KnowledgeSourceReference(name=KNOWLEDGE_SOURCE_NAME)\n",
    "        ],\n",
    "        models=[\n",
    "            KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    result_kb = index_client.create_or_update_knowledge_base(knowledge_base)\n",
    "    print(f\"   âœ… Knowledge Base ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"\\nğŸ“‹ Knowledge Base ì •ë³´:\")\n",
    "    print(f\"   ì´ë¦„: {KNOWLEDGE_BASE_NAME}\")\n",
    "    print(f\"   Knowledge Source: {KNOWLEDGE_SOURCE_NAME}\")\n",
    "    print(f\"   Search Index: {SEARCH_INDEX_NAME}\")\n",
    "    print(f\"   Output Mode: Answer Synthesis\")\n",
    "    \n",
    "    # configì— ì €ì¥\n",
    "    config[\"KNOWLEDGE_BASE_NAME\"] = KNOWLEDGE_BASE_NAME\n",
    "    config[\"KNOWLEDGE_SOURCE_NAME\"] = KNOWLEDGE_SOURCE_NAME\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Knowledge Base í™•ì¸:\")\n",
    "    print(f\"   https://portal.azure.com â†’ {SEARCH_NAME} â†’ Knowledge bases\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"   âš ï¸ Knowledge Base ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nğŸ’¡ ë¬¸ì œ í•´ê²°:\")\n",
    "    print(\"   1. ì»¤ë„ì„ ì¬ì‹œì‘í–ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. azure-search-documents í”„ë¦¬ë·° ë²„ì „(11.7.0b2)ì´ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. Azure OpenAI ëª¨ë¸ 'gpt-4.1'ê°€ ë°°í¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   4. Search API Key ê¶Œí•œì´ ì¶©ë¶„í•œì§€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84addc46",
   "metadata": {},
   "source": [
    "### KnowledgeAgent ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectionì— API Key ì„¤ì • (403 Forbidden í•´ê²°)\n",
    "print(\"ğŸ”‘ AI Search Connection API Key ì„¤ì • ì¤‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import requests\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "try:\n",
    "    # config íŒŒì¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ë¡œë“œ\n",
    "    config_file = '.foundry_config.json'\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    SEARCH_NAME = config.get(\"SEARCH_NAME\")\n",
    "    RESOURCE_GROUP = config.get(\"RESOURCE_GROUP\")\n",
    "    SUBSCRIPTION_ID = config.get(\"AZURE_SUBSCRIPTION_ID\") or config.get(\"SUBSCRIPTION_ID\")\n",
    "    PROJECT_ENDPOINT = config.get(\"PROJECT_ENDPOINT\") or config.get(\"FOUNDRY_ENDPOINT\")\n",
    "    \n",
    "    # AI Search API í‚¤ íšë“\n",
    "    print(f\"\\nğŸ” AI Search API Key ì¡°íšŒ ì¤‘...\")\n",
    "    result = subprocess.run([\n",
    "        \"az\", \"search\", \"admin-key\", \"show\",\n",
    "        \"--resource-group\", RESOURCE_GROUP,\n",
    "        \"--service-name\", SEARCH_NAME,\n",
    "        \"--query\", \"primaryKey\", \"-o\", \"tsv\"\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        raise Exception(f\"API Key ì¡°íšŒ ì‹¤íŒ¨: {result.stderr}\")\n",
    "    \n",
    "    api_key = result.stdout.strip()\n",
    "    print(f\"   âœ… API Key íšë“ ì™„ë£Œ\")\n",
    "    \n",
    "    # Project Connection ID í™•ì¸\n",
    "    from azure.ai.projects import AIProjectClient\n",
    "    credential = DefaultAzureCredential()\n",
    "    project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "    \n",
    "    connections = project_client.connections.list()\n",
    "    search_connections = [c for c in connections if 'search' in c.name.lower()]\n",
    "    \n",
    "    if not search_connections:\n",
    "        raise ValueError(\"AI Search Connectionì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    connection = search_connections[0]\n",
    "    CONNECTION_NAME = connection.name\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Connection ì—…ë°ì´íŠ¸ ì¤‘: {CONNECTION_NAME}\")\n",
    "    \n",
    "    # Connection ì—…ë°ì´íŠ¸ (REST API ì‚¬ìš©)\n",
    "    token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token.token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Project ë¦¬ì†ŒìŠ¤ ID ì¶”ì¶œ\n",
    "    project_id = PROJECT_ENDPOINT.split(\"/projects/\")[0].replace(\"https://\", \"\").replace(\".api.azureml.ms\", \"\")\n",
    "    project_name = PROJECT_ENDPOINT.split(\"/projects/\")[1]\n",
    "    \n",
    "    # Foundry ê³„ì • ì •ë³´ í™•ì¸\n",
    "    FOUNDRY_NAME = config.get(\"FOUNDRY_NAME\")\n",
    "    foundry_base_url = f\"https://management.azure.com/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.CognitiveServices/accounts/{FOUNDRY_NAME}\"\n",
    "    \n",
    "    # Connection URL\n",
    "    connection_url = f\"{foundry_base_url}/projects/{project_name}/connections/{CONNECTION_NAME}?api-version=2025-09-01\"\n",
    "    \n",
    "    # Connection ì •ë³´ ì¡°íšŒ\n",
    "    response = requests.get(connection_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        connection_data = response.json()\n",
    "        \n",
    "        # API Keyë¡œ ì—…ë°ì´íŠ¸\n",
    "        connection_data[\"properties\"][\"credentials\"] = {\n",
    "            \"type\": \"ApiKey\",\n",
    "            \"key\": api_key\n",
    "        }\n",
    "        \n",
    "        # Connection ì—…ë°ì´íŠ¸\n",
    "        update_response = requests.put(connection_url, headers=headers, json=connection_data)\n",
    "        \n",
    "        if update_response.status_code in [200, 201]:\n",
    "            print(f\"   âœ… Connection API Key ì„¤ì • ì™„ë£Œ!\")\n",
    "            print(f\"\\nğŸ’¡ ì´ì œ Agentê°€ Knowledge Baseì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ Connection ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_response.status_code}\")\n",
    "            print(f\"   ì‘ë‹µ: {update_response.text}\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ Connection ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}\")\n",
    "        print(f\"   ì‘ë‹µ: {response.text}\")\n",
    "        \n",
    "        # ëŒ€ì•ˆ: Portalì—ì„œ ìˆ˜ë™ ì„¤ì • ì•ˆë‚´\n",
    "        print(f\"\\nğŸ“ ìˆ˜ë™ ì„¤ì • ë°©ë²•:\")\n",
    "        print(f\"   1. https://ai.azure.com ì ‘ì†\")\n",
    "        print(f\"   2. Build â†’ Connections â†’ {CONNECTION_NAME} ì„ íƒ\")\n",
    "        print(f\"   3. 'Edit' í´ë¦­\")\n",
    "        print(f\"   4. Authentication ì„¹ì…˜ì—ì„œ 'API Key' ì„ íƒ\")\n",
    "        print(f\"   5. API Key ì…ë ¥ í›„ ì €ì¥\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… Connection ì„¤ì • ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ Connection ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n",
    "    print(f\"\\nğŸ’¡ ìˆ˜ë™ ì„¤ì •:\")\n",
    "    print(f\"   Portalì—ì„œ Connectionì˜ API Keyë¥¼ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d614c18",
   "metadata": {},
   "source": [
    "### Connection ìƒì„± (API Key ì¸ì¦)\n",
    "\n",
    "Agentê°€ Knowledge Baseì— ì ‘ê·¼í•˜ë ¤ë©´ AI Search Connectionì´ API Keyë¡œ ì¸ì¦ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e96287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– 3ë‹¨ê³„: KnowledgeAgent ìƒì„± ì¤‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition, MCPTool\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "try:\n",
    "    # config íŒŒì¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ë¡œë“œ\n",
    "    config_file = '.foundry_config.json'\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    PROJECT_ENDPOINT = config.get(\"PROJECT_ENDPOINT\") or config.get(\"FOUNDRY_ENDPOINT\")\n",
    "    SEARCH_NAME = config[\"SEARCH_NAME\"]\n",
    "    KNOWLEDGE_BASE_NAME = config.get(\"KNOWLEDGE_BASE_NAME\", \"foundry-knowledge-base\")\n",
    "    \n",
    "    # AIProjectClient ìƒì„± (Connection ì¡°íšŒìš©)\n",
    "    credential = DefaultAzureCredential()\n",
    "    project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "    \n",
    "    # Connection ì´ë¦„ í™•ì¸ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” Connection ì‚¬ìš©)\n",
    "    print(f\"\\nğŸ” í”„ë¡œì íŠ¸ Connection ëª©ë¡ í™•ì¸ ì¤‘...\")\n",
    "    connections = project_client.connections.list()\n",
    "    search_connections = [c for c in connections if 'search' in c.name.lower()]\n",
    "    \n",
    "    if not search_connections:\n",
    "        raise ValueError(f\"âŒ AI Search Connectionì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\n\"\n",
    "                        f\"ğŸ’¡ Portalì—ì„œ AI Search Connectionì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”:\\n\"\n",
    "                        f\"   https://ai.azure.com â†’ Build â†’ Connections â†’ + Connection â†’ Azure AI Search\")\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ Search Connection ì‚¬ìš©\n",
    "    PROJECT_CONNECTION_NAME = search_connections[0].name\n",
    "    print(f\"   âœ… Connection ë°œê²¬: {PROJECT_CONNECTION_NAME}\")\n",
    "    \n",
    "    # MCP ì—”ë“œí¬ì¸íŠ¸ URL (api-version í¬í•¨, API KeyëŠ” Connectionì„ í†µí•´ ì „ë‹¬)\n",
    "    MCP_ENDPOINT = f\"https://{SEARCH_NAME}.search.windows.net/knowledgebases/{KNOWLEDGE_BASE_NAME}/mcp?api-version=2025-11-01-preview\"\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Agent ì„¤ì •:\")\n",
    "    print(f\"   Project Endpoint: {PROJECT_ENDPOINT}\")\n",
    "    print(f\"   Connection: {PROJECT_CONNECTION_NAME}\")\n",
    "    print(f\"   MCP Endpoint: {MCP_ENDPOINT}\")\n",
    "    print(f\"\\nğŸ’¡ ì¸ì¦ ë°©ì‹: Connectionì„ í†µí•œ API Key ìë™ ì „ë‹¬\")\n",
    "    \n",
    "    # Agent Instructions (Microsoft ê¶Œì¥ í…œí”Œë¦¿)\n",
    "    KNOWLEDGE_INSTRUCTIONS = \"\"\"You are a helpful assistant that must use the knowledge base to answer all the questions from user. You must never answer from your own knowledge under any circumstances.\n",
    "\n",
    "Every answer must always provide annotations for using the MCP knowledge base tool and render them as: ã€message_idx:search_idxâ€ source_nameã€‘\n",
    "\n",
    "If you cannot find the answer in the provided knowledge base you must respond with \"I don't know\".\n",
    "\n",
    "í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    # MCP Tool ì„¤ì • (Connectionì„ í†µí•´ API Key ì „ë‹¬)\n",
    "    print(f\"\\nğŸ”§ MCP Tool êµ¬ì„± ì¤‘...\")\n",
    "    print(f\"   Server Label: knowledge-base\")\n",
    "    print(f\"   Connection ID: {PROJECT_CONNECTION_NAME} (API Key ì¸ì¦)\")\n",
    "    \n",
    "    mcp_kb_tool = MCPTool(\n",
    "        server_label=\"knowledge-base\",\n",
    "        server_url=MCP_ENDPOINT,\n",
    "        require_approval=\"never\",\n",
    "        allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "        project_connection_id=PROJECT_CONNECTION_NAME\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸš€ Agent ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # Agent ìƒì„±\n",
    "    agent = project_client.agents.create_version(\n",
    "        agent_name=\"KnowledgeAgent\",\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=\"gpt-5.1\",\n",
    "            instructions=KNOWLEDGE_INSTRUCTIONS,\n",
    "            tools=[mcp_kb_tool]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"   âœ… KnowledgeAgent ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"\\nğŸ“‹ Agent ì •ë³´:\")\n",
    "    print(f\"   ì´ë¦„: {agent.name}\")\n",
    "    print(f\"   ë²„ì „: {agent.version}\")\n",
    "    print(f\"   ëª¨ë¸: gpt-5.1\")\n",
    "    print(f\"   MCP Tool: knowledge_base_retrieve\")\n",
    "    \n",
    "    # configì— ì €ì¥\n",
    "    config[\"AGENT_NAME\"] = agent.name\n",
    "    config[\"AGENT_VERSION\"] = agent.version\n",
    "    config[\"PROJECT_CONNECTION_NAME\"] = PROJECT_CONNECTION_NAME  # ì‹¤ì œ Connection ì´ë¦„ ì €ì¥\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Agent í™•ì¸:\")\n",
    "    print(f\"   https://ai.azure.com â†’ Build â†’ Agents â†’ {agent.name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"   âš ï¸ Agent ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nğŸ’¡ ë¬¸ì œ í•´ê²°:\")\n",
    "    print(\"   1. Project Connectionì´ ë¨¼ì € ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. Managed Identity ê¶Œí•œì´ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. Azure CLI ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸\")\n",
    "    print(\"   4. gpt-5.1 ëª¨ë¸ì´ ë°°í¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c8d7e",
   "metadata": {},
   "source": [
    "### Agent í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d983a",
   "metadata": {},
   "source": [
    "> **âš ï¸ ì‹¤í–‰ ì „ í•„ìˆ˜ ì‘ì—…**: [Azure AI Foundry Portal](https://ai.azure.com)ì—ì„œ `foundry-knowledge-base` Knowledge Baseë¥¼ Projectì— ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KnowledgeAgent í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª 4ë‹¨ê³„: KnowledgeAgent í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # Agent ë³€ìˆ˜ ê²€ì¦\n",
    "    if 'agent' in locals():\n",
    "        knowledge_agent = agent\n",
    "        print(f\"âœ… Agent ë³€ìˆ˜ ì‚¬ìš©: {knowledge_agent.name} (version: {knowledge_agent.version})\")\n",
    "    elif 'knowledge_agent' not in locals():\n",
    "        raise NameError(\"knowledge_agentê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìœ„ì˜ KnowledgeAgent ìƒì„± ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    # OpenAI Client ê²€ì¦\n",
    "    if 'openai_client' not in locals():\n",
    "        raise NameError(\"OpenAI clientê°€ ì—†ìŠµë‹ˆë‹¤. Setup ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    # Test Questions (ì²« ë²ˆì§¸ë§Œ í…ŒìŠ¤íŠ¸)\n",
    "    test_questions = [\n",
    "        \"PerkPlusê°€ ì»¤ë²„í•˜ëŠ” í•­ëª©ë“¤ì„ ì•Œë ¤ì¤˜\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n[ì§ˆë¬¸ {i}]: {question}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Conversation ìƒì„±\n",
    "        conversation = openai_client.conversations.create()\n",
    "        \n",
    "        # Agentë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±\n",
    "        print(f\"  ì‘ë‹µ ìƒì„± ì¤‘...\", flush=True)\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            input=question,\n",
    "            extra_body={\"agent\": {\"name\": knowledge_agent.name, \"type\": \"agent_reference\"}}\n",
    "        )\n",
    "        \n",
    "        # DEBUG: Response ìƒíƒœ í™•ì¸\n",
    "        print(f\"\\nğŸ” Response ìƒíƒœ: {response.status}\")\n",
    "        print(f\"ğŸ” Response ID: {response.id}\")\n",
    "        \n",
    "        if hasattr(response, 'output') and isinstance(response.output, list):\n",
    "            print(f\"ğŸ” Output ê¸¸ì´: {len(response.output)}\")\n",
    "            for idx, item in enumerate(response.output):\n",
    "                print(f\"\\n  Item {idx}: {item.__class__.__name__}\")\n",
    "                if hasattr(item, 'type'):\n",
    "                    print(f\"    type: {item.type}\")\n",
    "                if hasattr(item, 'id'):\n",
    "                    print(f\"    id: {item.id}\")\n",
    "                if hasattr(item, 'text'):\n",
    "                    print(f\"    text (ì²˜ìŒ 100ì): {item.text[:100]}\")\n",
    "                if item.__class__.__name__ == 'McpApprovalRequest':\n",
    "                    print(f\"    âš ï¸ Approval í•„ìš”!\")\n",
    "                    print(f\"    name: {item.name if hasattr(item, 'name') else 'N/A'}\")\n",
    "                    print(f\"    arguments: {item.arguments[:200] if hasattr(item, 'arguments') else 'N/A'}\")\n",
    "        \n",
    "        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        actual_text = \"\"\n",
    "        \n",
    "        if hasattr(response, 'output') and isinstance(response.output, list):\n",
    "            for item in response.output:\n",
    "                if hasattr(item, 'text'):\n",
    "                    actual_text = item.text\n",
    "                    break\n",
    "        \n",
    "        print(f\"\\n[ì‘ë‹µ]: {actual_text if actual_text else 'âš ï¸ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}\\n\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"âœ… KnowledgeAgent í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ac472",
   "metadata": {},
   "source": [
    "## Azure Blob Storage ê¸°ë°˜ Knowledge Base\n",
    "\n",
    "Blob Storageë¥¼ ì§ì ‘ ì—°ê²°í•˜ì—¬ ë” ê°„ë‹¨í•˜ê²Œ Knowledge Baseë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6eb456",
   "metadata": {},
   "source": [
    "### 1. Storage Account ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config íŒŒì¼ì—ì„œ Storage Account ì´ë¦„ ë¡œë“œ\n",
    "try:\n",
    "    STORAGE_NAME = config.get(\"STORAGE_NAME\")\n",
    "    if not STORAGE_NAME:\n",
    "        raise ValueError(\"STORAGE_NAMEì´ configì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "except:\n",
    "    print(\"âš ï¸ configì—ì„œ STORAGE_NAMEì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ìœ„ì˜ 'í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ' ì…€ê³¼ 'AI Search ë° Storage ë¦¬ì†ŒìŠ¤ ì´ë¦„ ìƒì„±' ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# Container ì´ë¦„ ì„¤ì •\n",
    "CONTAINER_NAME = \"documents\"\n",
    "\n",
    "print(f\"Storage Account: {STORAGE_NAME}\")\n",
    "print(f\"Container: {CONTAINER_NAME}\")\n",
    "print(f\"\\nâœ… ì´ë¯¸ ìƒì„±ëœ Storage Accountì™€ Containerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "print(f\"ğŸ’¡ ë™ì¼í•œ Blob Storageë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043bb11c",
   "metadata": {},
   "source": [
    "### 2. Knowledge Source ìƒì„± (Blob Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AzureBlobKnowledgeSource,\n",
    "    AzureBlobKnowledgeSourceParameters,\n",
    "    KnowledgeSourceIngestionParameters,\n",
    "    KnowledgeSourceContentExtractionMode,\n",
    "    KnowledgeSourceAzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters\n",
    ")\n",
    "\n",
    "# Knowledge Source ì´ë¦„\n",
    "BLOB_KNOWLEDGE_SOURCE_NAME = \"ks-azureblob-200\"\n",
    "\n",
    "print(\"Knowledge Source ìƒì„± ì¤‘...\")\n",
    "print(f\"ì´ë¦„: {BLOB_KNOWLEDGE_SOURCE_NAME}\")\n",
    "\n",
    "try:\n",
    "    # Storage Account Resource ID êµ¬ì„±\n",
    "    storage_resource_id = f\"/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.Storage/storageAccounts/{STORAGE_NAME}\"\n",
    "    \n",
    "    # Embedding Model (Vectorizer) ì„¤ì •\n",
    "    aoai_vectorizer_params = AzureOpenAIVectorizerParameters(\n",
    "        resource_url=FOUNDRY_ENDPOINT,\n",
    "        deployment_name=\"text-embedding-3-large\",\n",
    "        model_name=\"text-embedding-3-large\"\n",
    "    )\n",
    "    \n",
    "    embedding_vectorizer = KnowledgeSourceAzureOpenAIVectorizer(\n",
    "        azure_open_ai_parameters=aoai_vectorizer_params\n",
    "    )\n",
    "    \n",
    "    # Ingestion íŒŒë¼ë¯¸í„° ì„¤ì • (System-Assigned MIëŠ” identity íŒŒë¼ë¯¸í„° ë¶ˆí•„ìš”)\n",
    "    ingestion_params = KnowledgeSourceIngestionParameters(\n",
    "        content_extraction_mode=KnowledgeSourceContentExtractionMode.MINIMAL,\n",
    "        embedding_model=embedding_vectorizer\n",
    "    )\n",
    "    \n",
    "    # Blob Storage íŒŒë¼ë¯¸í„° ì„¤ì • (Managed Identity Connection String ì‚¬ìš©)\n",
    "    # System-Assigned Managed Identityë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ResourceId í˜•ì‹ì˜ connection stringë§Œ í•„ìš”\n",
    "    managed_identity_connection_string = f\"ResourceId={storage_resource_id};\"\n",
    "    \n",
    "    blob_params = AzureBlobKnowledgeSourceParameters(\n",
    "        connection_string=managed_identity_connection_string,\n",
    "        container_name=CONTAINER_NAME,\n",
    "        ingestion_parameters=ingestion_params\n",
    "    )\n",
    "    \n",
    "    # Blob Storage ê¸°ë°˜ Knowledge Source ìƒì„±\n",
    "    blob_knowledge_source = AzureBlobKnowledgeSource(\n",
    "        name=BLOB_KNOWLEDGE_SOURCE_NAME,\n",
    "        azure_blob_parameters=blob_params,\n",
    "        description=\"Blob Storage ê¸°ë°˜ Knowledge Source\"\n",
    "    )\n",
    "    \n",
    "    # Knowledge Source ìƒì„±\n",
    "    result_blob_ks = index_client.create_knowledge_source(blob_knowledge_source)\n",
    "    \n",
    "    print(f\"\\nâœ… Knowledge Source ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"   - ì´ë¦„: {result_blob_ks.name}\")\n",
    "    print(f\"   - íƒ€ì…: Blob Storage\")\n",
    "    print(f\"   - Container: {CONTAINER_NAME}\")\n",
    "    print(f\"   - Embedding ëª¨ë¸: text-embedding-3-large\")\n",
    "    print(f\"\\nğŸ’¡ ì´ Knowledge SourceëŠ” Blob Storageì˜ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì¸ë±ì‹±í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ Knowledge Source ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. Storage Accountì™€ Containerê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\")\n",
    "    print(\"   2. AI Search Managed Identityê°€ Storageì— ëŒ€í•œ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. FOUNDRY_ENDPOINTê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   4. ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17a29c",
   "metadata": {},
   "source": [
    "### 3. Knowledge Base ìƒì„± (Blob Storage ê¸°ë°˜)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64459a73",
   "metadata": {},
   "source": [
    "> **âš ï¸ ì‹¤í–‰ ì „ í•„ìˆ˜ ì‘ì—…**: [Azure AI Foundry Portal](https://ai.azure.com)ì—ì„œ `blob-knowledge-base` Knowledge Baseë¥¼ Projectì— ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    KnowledgeSourceReference,\n",
    "    KnowledgeBaseAzureOpenAIModel\n",
    ")\n",
    "\n",
    "# Knowledge Base ì´ë¦„\n",
    "BLOB_KNOWLEDGE_BASE_NAME = \"knowledgebase200\"\n",
    "\n",
    "print(\"Knowledge Base ìƒì„± ì¤‘...\")\n",
    "print(f\"ì´ë¦„: {BLOB_KNOWLEDGE_BASE_NAME}\")\n",
    "\n",
    "try:\n",
    "    # Azure OpenAI ëª¨ë¸ ì„¤ì • (Answer Synthesisìš©)\n",
    "    aoai_model_params = AzureOpenAIVectorizerParameters(\n",
    "        resource_url=FOUNDRY_ENDPOINT,\n",
    "        deployment_name=\"gpt-5.1\",\n",
    "        model_name=\"gpt-5.1\"\n",
    "    )\n",
    "    \n",
    "    # Knowledge Base ìƒì„± (Blob Storage ê¸°ë°˜)\n",
    "    blob_knowledge_base = KnowledgeBase(\n",
    "        name=BLOB_KNOWLEDGE_BASE_NAME,\n",
    "        description=\"Blob Storage ê¸°ë°˜ Knowledge Base\",\n",
    "        retrieval_instructions=\"ì´ ì§€ì‹ ê¸°ë°˜ì€ Blob Storageì˜ ë¬¸ì„œë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
    "        answer_instructions=\"ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\",\n",
    "        output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,\n",
    "        knowledge_sources=[\n",
    "            KnowledgeSourceReference(name=BLOB_KNOWLEDGE_SOURCE_NAME)\n",
    "        ],\n",
    "        models=[\n",
    "            KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_model_params)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Knowledge Base ìƒì„±\n",
    "    result_blob_kb = index_client.create_or_update_knowledge_base(blob_knowledge_base)\n",
    "    \n",
    "    print(f\"\\nâœ… Knowledge Base ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"   - ì´ë¦„: {result_blob_kb.name}\")\n",
    "    print(f\"   - Output Mode: {result_blob_kb.output_mode}\")\n",
    "    print(f\"   - Knowledge Source: {BLOB_KNOWLEDGE_SOURCE_NAME}\")\n",
    "    print(f\"   - ëª¨ë¸: gpt-5.1\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ Knowledge Base ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. Knowledge Sourceê°€ ë¨¼ì € ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©\")\n",
    "    print(\"   3. Chat ëª¨ë¸ ì´ë¦„ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36c800",
   "metadata": {},
   "source": [
    "### 4. KnowledgeAgent2 ìƒì„± (Blob Storage ê¸°ë°˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac280c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_AGENT_2_NAME = \"KnowledgeAgent2\"\n",
    "\n",
    "print(\"KnowledgeAgent2 ìƒì„± ì¤‘...\")\n",
    "print(f\"Knowledge Base: {BLOB_KNOWLEDGE_BASE_NAME}\")\n",
    "\n",
    "try:\n",
    "    # MCP Tool ì •ì˜ (Blob Storage ê¸°ë°˜ Knowledge Base)\n",
    "    mcp_blob_kb_tool = MCPTool(\n",
    "        server_label=\"knowledge-base-blob\",\n",
    "        server_url=MCP_ENDPOINT,\n",
    "        require_approval=\"never\",\n",
    "        allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "        project_connection_id=PROJECT_CONNECTION_NAME\n",
    "    )\n",
    "    \n",
    "    # Agent ìƒì„±\n",
    "    blob_knowledge_agent = project_client.agents.create_version(\n",
    "        agent_name=KNOWLEDGE_AGENT_2_NAME,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=\"model-router\",\n",
    "            instructions=KNOWLEDGE_INSTRUCTIONS,\n",
    "            tools=[mcp_blob_kb_tool]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… {KNOWLEDGE_AGENT_2_NAME} ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"   - Agent: {KNOWLEDGE_AGENT_2_NAME}\")\n",
    "    print(f\"   - Model: model-router\")\n",
    "    print(f\"   - Knowledge Base: {BLOB_KNOWLEDGE_BASE_NAME}\")\n",
    "    print(f\"   - ë°ì´í„° ì†ŒìŠ¤: Blob Storage\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ Agent ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. Knowledge Baseê°€ ë¨¼ì € ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. MCP endpoint í™•ì¸\")\n",
    "    print(\"   3. PROJECT_CONNECTION_NAMEì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066e4ef",
   "metadata": {},
   "source": [
    "### 5. KnowledgeAgent2 í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1796bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"KnowledgeAgent2 í…ŒìŠ¤íŠ¸ (Blob Storage ê¸°ë°˜)\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "try:\n",
    "    # OpenAI client ê°€ì ¸ì˜¤ê¸°\n",
    "    openai_client = project_client.get_openai_client()\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n[ì§ˆë¬¸ {i}]: {question}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Conversation ìƒì„±\n",
    "        conversation = openai_client.conversations.create()\n",
    "        \n",
    "        # Agentë¥¼ í†µí•´ ì‘ë‹µ ìƒì„± (Rate limit ì¬ì‹œë„ ë¡œì§ í¬í•¨)\n",
    "        print(f\"  ì‘ë‹µ ìƒì„± ì¤‘...\", flush=True)\n",
    "        \n",
    "        max_retries = 3\n",
    "        retry_delay = 15  # ì´ˆ\n",
    "        response = None\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = openai_client.responses.create(\n",
    "                    conversation=conversation.id,\n",
    "                    input=question,\n",
    "                    extra_body={\"agent\": {\"name\": blob_knowledge_agent.name, \"type\": \"agent_reference\"}}\n",
    "                )\n",
    "                print(f\"  âœ… ì‘ë‹µ ìƒì„± ì„±ê³µ!\")\n",
    "                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_message = str(e)\n",
    "                if \"429\" in error_message or \"Too Many Requests\" in error_message:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        wait_time = retry_delay * (attempt + 1)\n",
    "                        print(f\"  â³ Rate limit ë„ë‹¬. {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"  âŒ {max_retries}ë²ˆ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨.\")\n",
    "                        print(f\"  ğŸ’¡ 5ë¶„ ì •ë„ ê¸°ë‹¤ë¦° í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "                        raise\n",
    "                else:\n",
    "                    # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ë°”ë¡œ throw\n",
    "                    raise\n",
    "        \n",
    "        if response is None:\n",
    "            print(\"âš ï¸ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            continue\n",
    "        \n",
    "        # DEBUG: Response ìƒíƒœ í™•ì¸\n",
    "        print(f\"\\nğŸ” Response ìƒíƒœ: {response.status}\")\n",
    "        print(f\"ğŸ” Response ID: {response.id}\")\n",
    "        \n",
    "        if hasattr(response, 'output') and isinstance(response.output, list):\n",
    "            print(f\"ğŸ” Output ê¸¸ì´: {len(response.output)}\")\n",
    "            for idx, item in enumerate(response.output):\n",
    "                print(f\"\\n  Item {idx}: {item.__class__.__name__}\")\n",
    "                if hasattr(item, 'type'):\n",
    "                    print(f\"    type: {item.type}\")\n",
    "                if hasattr(item, 'id'):\n",
    "                    print(f\"    id: {item.id}\")\n",
    "                if hasattr(item, 'text'):\n",
    "                    print(f\"    text (ì²˜ìŒ 100ì): {item.text[:100]}\")\n",
    "                if item.__class__.__name__ == 'McpApprovalRequest':\n",
    "                    print(f\"    âš ï¸ Approval í•„ìš”!\")\n",
    "                    print(f\"    name: {item.name if hasattr(item, 'name') else 'N/A'}\")\n",
    "                    print(f\"    arguments: {item.arguments[:200] if hasattr(item, 'arguments') else 'N/A'}\")\n",
    "        \n",
    "        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        actual_text = \"\"\n",
    "        \n",
    "        if hasattr(response, 'output') and isinstance(response.output, list):\n",
    "            for item in response.output:\n",
    "                if hasattr(item, 'text'):\n",
    "                    actual_text = item.text\n",
    "                    break\n",
    "        \n",
    "        print(f\"\\n[ì‘ë‹µ]: {actual_text if actual_text else 'âš ï¸ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}\\n\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"âœ… KnowledgeAgent2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nâš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nìƒì„¸ ì˜¤ë¥˜:\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0464e",
   "metadata": {},
   "source": [
    "### ğŸ“ ë‘ ë°©ì‹ ë¹„êµ\n",
    "\n",
    "| íŠ¹ì§• | AI Search Index | Blob Storage ì§ì ‘ ì—°ê²° |\n",
    "|------|----------------|----------------------|\n",
    "| **ì„¤ì • ë³µì¡ë„** | ë†’ìŒ (Import Wizard í•„ìš”) | ë‚®ìŒ (ê°„ë‹¨í•œ ì„¤ì •) |\n",
    "| **ìë™ ì—…ë°ì´íŠ¸** | ìˆ˜ë™ ì¬ì¸ë±ì‹± í•„ìš” | ìë™ ê°ì§€ ë° ì¸ë±ì‹± |\n",
    "| **ì»¤ìŠ¤í„°ë§ˆì´ì§•** | ë†’ìŒ (í•„ë“œ, ìŠ¤í‚¤ë§ˆ ë“±) | ë‚®ìŒ (ìë™ êµ¬ì„±) |\n",
    "| **ì„±ëŠ¥** | ë†’ìŒ (ìµœì í™” ê°€ëŠ¥) | ì¤‘ê°„ |\n",
    "| **ì‚¬ìš© ì‚¬ë¡€** | ë³µì¡í•œ ê²€ìƒ‰ ìš”êµ¬ì‚¬í•­ | ê°„ë‹¨í•œ ë¬¸ì„œ ê²€ìƒ‰ |\n",
    "\n",
    "**ê¶Œì¥ ì‚¬í•­:**\n",
    "- ë³µì¡í•œ ê²€ìƒ‰ ë° í•„í„°ë§ì´ í•„ìš”í•œ ê²½ìš° â†’ AI Search Index\n",
    "- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ë° ê°„ë‹¨í•œ ë¬¸ì„œ ê²€ìƒ‰ â†’ Blob Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a84a2f",
   "metadata": {},
   "source": [
    "## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤\n",
    "\n",
    "- [Foundry IQ ê°œìš”](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/knowledge-retrieval?view=foundry&tabs=foundry%2Cpython)\n",
    "- [Azure AI Search ë¬¸ì„œ](https://learn.microsoft.com/en-us/azure/search/)\n",
    "- [RAG íŒ¨í„´ ê°€ì´ë“œ](https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview?tabs=docs)\n",
    "- [ë²¡í„° ê²€ìƒ‰ ìµœì í™”](https://learn.microsoft.com/en-us/azure/search/vector-search-overview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
