{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8dae378",
   "metadata": {},
   "source": [
    "> âš ï¸ **ì‘ì—… ì¤‘ (Work in Progress)**: ì´ ë…¸íŠ¸ë¶ì€ í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. ì¼ë¶€ ì½”ë“œê°€ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581af05",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ëª©ì°¨\n",
    "\n",
    "- [í‰ê°€ ê°œìš”](#í‰ê°€-ê°œìš”)\n",
    "- [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)\n",
    "- [í‰ê°€ ê¸°ì¤€ ì´í•´](#í‰ê°€-ê¸°ì¤€-ì´í•´)\n",
    "- [í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ ë¶„ì„](#í‰ê°€-ì‹¤í–‰-ë°-ê²°ê³¼-ë¶„ì„)\n",
    "- [í‰ê°€ ëª¨ë²” ì‚¬ë¡€](#í‰ê°€-ëª¨ë²”-ì‚¬ë¡€)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5017c3a",
   "metadata": {},
   "source": [
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- AI ì—ì´ì „íŠ¸ í‰ê°€ì˜ ì¤‘ìš”ì„± ì´í•´\n",
    "- Foundryì˜ ìë™ í‰ê°€ ê¸°ëŠ¥ í™œìš©\n",
    "- ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œì˜ ì˜ë¯¸ì™€ í™œìš©ë²• í•™ìŠµ\n",
    "- í•©ì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ í‰ê°€ ìˆ˜í–‰\n",
    "- í‰ê°€ ê²°ê³¼ í•´ì„ ë° ê°œì„  ë°©ì•ˆ ë„ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c7789",
   "metadata": {},
   "source": [
    "## â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„\n",
    "\n",
    "ì•½ 10ë¶„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e4141",
   "metadata": {},
   "source": [
    "## í‰ê°€ ê°œìš”\n",
    "\n",
    "### ì™œ í‰ê°€ê°€ ì¤‘ìš”í•œê°€?\n",
    "\n",
    "AI ì—ì´ì „íŠ¸ë¥¼ í”„ë¡œë•ì…˜ì— ë°°í¬í•˜ê¸° ì „ì— ë‹¤ìŒ ì‚¬í•­ì„ ê²€ì¦í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "```\n",
    "ì •í™•ì„± â†’ ê´€ë ¨ì„± â†’ ì¼ê´€ì„± â†’ ìì—°ìŠ¤ëŸ¬ì›€ â†’ ì•ˆì „ì„±\n",
    "```\n",
    "\n",
    "í‰ê°€ ì—†ì´ ë°°í¬í•˜ë©´:\n",
    "- âŒ ë¶€ì •í™•í•œ ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©ì ì‹ ë¢° ì €í•˜\n",
    "- âŒ ê´€ë ¨ ì—†ëŠ” ì‘ë‹µìœ¼ë¡œ ì‚¬ìš©ì ê²½í—˜ ì•…í™”\n",
    "- âŒ ì¼ê´€ì„± ì—†ëŠ” í’ˆì§ˆë¡œ ë¸Œëœë“œ ì´ë¯¸ì§€ ì†ìƒ\n",
    "- âŒ ë¶€ì ì ˆí•œ ì½˜í…ì¸  ìƒì„±ìœ¼ë¡œ ë²•ì  ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453488ac",
   "metadata": {},
   "source": [
    "### Microsoft Foundryì˜ í‰ê°€ ê¸°ëŠ¥\n",
    "\n",
    "FoundryëŠ” ë‹¤ìŒì„ ìë™í™”í•©ë‹ˆë‹¤:\n",
    "- âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (Synthetic generation)\n",
    "- âœ… ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ ì ìš©\n",
    "- âœ… ëŒ€ê·œëª¨ í‰ê°€ ì‹¤í–‰\n",
    "- âœ… ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb173e73",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •\n",
    "\n",
    "í‰ê°€ë¥¼ ìœ„í•œ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27edc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# PATH í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Azure CLIë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡)\n",
    "possible_paths = [\n",
    "    \"/opt/homebrew/bin\",  # macOS (Apple Silicon)\n",
    "    \"/usr/local/bin\",     # macOS (Intel) / Linux\n",
    "    \"/usr/bin\",           # Linux / GitHub Codespaces\n",
    "    \"/home/linuxbrew/.linuxbrew/bin\"  # Linux Homebrew\n",
    "]\n",
    "\n",
    "az_path = None\n",
    "try:\n",
    "    result = subprocess.run(['which', 'az'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        az_path = os.path.dirname(result.stdout.strip())\n",
    "except:\n",
    "    pass\n",
    "\n",
    "paths_to_add = []\n",
    "if az_path and az_path not in os.environ.get(\"PATH\", \"\"):\n",
    "    paths_to_add.append(az_path)\n",
    "else:\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path) and path not in os.environ.get(\"PATH\", \"\"):\n",
    "            paths_to_add.append(path)\n",
    "\n",
    "if paths_to_add:\n",
    "    new_path = \":\".join(paths_to_add) + \":\" + os.environ.get(\"PATH\", \"\")\n",
    "    os.environ[\"PATH\"] = new_path\n",
    "\n",
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ì €ì¥í•œ ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "config_file = \".foundry_config.json\"\n",
    "try:\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "    FOUNDRY_NAME = config.get(\"FOUNDRY_NAME\")\n",
    "    RESOURCE_GROUP = config.get(\"RESOURCE_GROUP\")\n",
    "    LOCATION = config.get(\"LOCATION\")\n",
    "    TENANT_ID = config.get(\"TENANT_ID\")\n",
    "    PROJECT_NAME = config.get(\"PROJECT_NAME\", \"proj-default\")\n",
    "    PROJECT_ENDPOINT = config.get(\"FOUNDRY_ENDPOINT\")\n",
    "    \n",
    "    # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • (ë‹¤ë¥¸ ë„êµ¬ë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)\n",
    "    os.environ[\"FOUNDRY_NAME\"] = FOUNDRY_NAME\n",
    "    os.environ[\"LOCATION\"] = LOCATION\n",
    "    os.environ[\"RESOURCE_GROUP\"] = RESOURCE_GROUP\n",
    "    os.environ[\"AZURE_SUBSCRIPTION_ID\"] = config.get(\"AZURE_SUBSCRIPTION_ID\", \"\")\n",
    "    os.environ[\"_ENDPOINT\"] = PROJECT_ENDPOINT\n",
    "    \n",
    "    print(f\"âœ… ì„¤ì • íŒŒì¼ '{config_file}'ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"\\nğŸ“Œ Foundry Name: {FOUNDRY_NAME}\")\n",
    "    print(f\"ğŸ“Œ Resource Group: {RESOURCE_GROUP}\")\n",
    "    print(f\"ğŸ“Œ Location: {LOCATION}\")\n",
    "    print(f\"ğŸ“Œ í”„ë¡œì íŠ¸ ì—”ë“œí¬ì¸íŠ¸: {PROJECT_ENDPOINT}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âš ï¸ '{config_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ 01-setup.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ í™˜ê²½ì„ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install -q azure-ai-evaluation azure-ai-projects azure-identity\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‚¬ìš©í•  í”„ë¡œì íŠ¸ ì—”ë“œí¬ì¸íŠ¸: {PROJECT_ENDPOINT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ ì—ì´ì „íŠ¸ í‰ê°€ ì˜ˆì œ\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "test_queries = [\n",
    "    \"Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì„œìš¸ì˜ ì¸êµ¬ëŠ” ëª‡ ëª…ì¸ê°€ìš”?\",\n",
    "    \"ìµœê·¼ AI ê¸°ìˆ  ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "    \"í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ìë™ìœ¼ë¡œ ModelRouterAgent ì°¾ê¸°\n",
    "try:\n",
    "    agents = list(project_client.agents.list())\n",
    "    agent_router = next((a for a in agents if a.name == \"ModelRouterAgent\"), None)\n",
    "    \n",
    "    if not agent_router:\n",
    "        print(\"âš ï¸ 'ModelRouterAgent'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ 03-agents.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.\")\n",
    "        raise ValueError(\"Agent not found\")\n",
    "    \n",
    "    print(f\"âœ… ì‚¬ìš©í•  ì—ì´ì „íŠ¸: {agent_router.name} (ID: {agent_router.id})\\n\")\n",
    "    \n",
    "    # ë°ëª¨ìš© Mock ì‘ë‹µ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Portal í‰ê°€ ê¶Œì¥)\n",
    "    print(\"\\nğŸ’¡ ì°¸ê³ : SDK ë²„ì „ ì œí•œìœ¼ë¡œ ì¸í•´ Mock ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    print(\"   ì‹¤ì œ ëŒ€ê·œëª¨ í‰ê°€ëŠ” Azure Portalì„ ì‚¬ìš©í•˜ì„¸ìš”.\\n\")\n",
    "    \n",
    "    mock_responses = [\n",
    "        \"Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ë ¤ë©´ `sort()` ë©”ì„œë“œë‚˜ `sorted()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `list.sort()`ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì œìë¦¬ì—ì„œ ì •ë ¬í•˜ê³ , `sorted(list)`ëŠ” ìƒˆë¡œìš´ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
    "        \"ë¨¸ì‹ ëŸ¬ë‹ì€ ëª…ì‹œì  í”„ë¡œê·¸ë˜ë° ì—†ì´ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì´ë©°, ë”¥ëŸ¬ë‹ì€ ì¸ê³µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ë” ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ ë” ë§ì€ ë°ì´í„°ì™€ ì»´í“¨íŒ… íŒŒì›Œê°€ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "        \"ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 950ë§Œ ëª…ì…ë‹ˆë‹¤. (2023ë…„ ê¸°ì¤€)\",\n",
    "        \"ìµœê·¼ AI ê¸°ìˆ  ë™í–¥ìœ¼ë¡œëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „, ë©€í‹°ëª¨ë‹¬ AI, ìƒì„±í˜• AIì˜ í™•ì‚°, AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë°œì „ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "        \"í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì˜ ì£¼ìš” ì¥ì ì€ í™•ì¥ì„±, ë¹„ìš© íš¨ìœ¨ì„±, ì ‘ê·¼ì„±, ìë™ ì—…ë°ì´íŠ¸, ì¬í•´ ë³µêµ¬ ê¸°ëŠ¥ ë“±ì…ë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ ë¦¬ì†ŒìŠ¤ë¥¼ ìœ ì—°í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆì–´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\"\n",
    "    ]\n",
    "    \n",
    "    responses = []\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n[ì§ˆë¬¸ {i}/{len(test_queries)}]: {query}\")\n",
    "        response = mock_responses[i-1]\n",
    "        responses.append({\"query\": query, \"response\": response})\n",
    "        print(f\"[ì‘ë‹µ]: {response[:100]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"\\nâœ… {len(test_queries)}ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    print(f\"\\nğŸ’¡ í¬í„¸ì—ì„œ ë” ìì„¸í•œ í‰ê°€ë¥¼ ì§„í–‰í•˜ì„¸ìš”:\")\n",
    "    print(\"   https://ai.azure.com > Build > Evaluations\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. 03-agents.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ModelRouterAgentë¥¼ ìƒì„±\")\n",
    "    print(\"   2. Azureì— ë¡œê·¸ì¸í–ˆëŠ”ì§€ í™•ì¸ (az login)\")\n",
    "    print(\"   3. FOUNDRY_NAMEì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f8c6a",
   "metadata": {},
   "source": [
    "### Azure AI Evaluation SDK ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "SDKë¥¼ í†µí•´ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ í‰ê°€ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ Evaluatorë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‘ë‹µì˜ í’ˆì§ˆì„ ì¸¡ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc979c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Evaluation SDK Evaluator ì„í¬íŠ¸\n",
    "from azure.ai.evaluation import (\n",
    "    CoherenceEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    RelevanceEvaluator,\n",
    ")\n",
    "\n",
    "# Azure OpenAI ëª¨ë¸ ì„¤ì • (í‰ê°€ìš©)\n",
    "model_config = {\n",
    "    \"azure_endpoint\": f\"https://{FOUNDRY_NAME}.openai.azure.com/\",\n",
    "    \"api_version\": \"2024-08-01-preview\",\n",
    "    \"azure_deployment\": \"gpt-5.1\",  # í‰ê°€ì— ì‚¬ìš©í•  ëª¨ë¸ (í•˜ì´í”ˆ í¬í•¨)\n",
    "}\n",
    "\n",
    "# Evaluator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "coherence_evaluator = CoherenceEvaluator(model_config=model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config=model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config=model_config)\n",
    "relevance_evaluator = RelevanceEvaluator(model_config=model_config)\n",
    "\n",
    "print(\"âœ… Evaluator ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "print(\"   - CoherenceEvaluator: ë…¼ë¦¬ì  ì¼ê´€ì„± í‰ê°€\")\n",
    "print(\"   - FluencyEvaluator: ìì—°ìŠ¤ëŸ¬ì›€ í‰ê°€\")\n",
    "print(\"   - GroundednessEvaluator: ì‚¬ì‹¤ ê¸°ë°˜ í‰ê°€\")\n",
    "print(\"   - RelevanceEvaluator: ê´€ë ¨ì„± í‰ê°€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd03ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ì‹¤í–‰ ì˜ˆì œ\n",
    "# ìœ„ì—ì„œ ìˆ˜ì§‘í•œ responses ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤\n",
    "\n",
    "print(\"ğŸ“Š SDK ê¸°ë°˜ í‰ê°€ ì‹¤í–‰ ì¤‘...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, item in enumerate(responses, 1):\n",
    "    query = item[\"query\"]\n",
    "    response = item[\"response\"]\n",
    "    \n",
    "    # í‰ê°€ìš© ì»¨í…ìŠ¤íŠ¸ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” RAGì—ì„œ ê°€ì ¸ì˜¨ ë¬¸ì„œ ì‚¬ìš©)\n",
    "    context = \"ì¼ë°˜ì ì¸ ì§€ì‹ ê¸°ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    print(f\"\\n[ìƒ˜í”Œ {i}/{len(responses)}]\")\n",
    "    print(f\"ì§ˆë¬¸: {query[:50]}...\")\n",
    "    \n",
    "    # ê° Evaluatorë¡œ í‰ê°€\n",
    "    coherence_score = coherence_evaluator(query=query, response=response)\n",
    "    fluency_score = fluency_evaluator(query=query, response=response)\n",
    "    groundedness_score = groundedness_evaluator(query=query, response=response, context=context)\n",
    "    relevance_score = relevance_evaluator(query=query, response=response, context=context)\n",
    "    \n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"response\": response[:100],\n",
    "        \"coherence\": coherence_score.get(\"coherence\", \"N/A\"),\n",
    "        \"fluency\": fluency_score.get(\"fluency\", \"N/A\"),\n",
    "        \"groundedness\": groundedness_score.get(\"groundedness\", \"N/A\"),\n",
    "        \"relevance\": relevance_score.get(\"relevance\", \"N/A\"),\n",
    "    }\n",
    "    evaluation_results.append(result)\n",
    "    \n",
    "    print(f\"  Coherence: {result['coherence']}/5\")\n",
    "    print(f\"  Fluency: {result['fluency']}/5\")\n",
    "    print(f\"  Groundedness: {result['groundedness']}/5\")\n",
    "    print(f\"  Relevance: {result['relevance']}/5\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nâœ… {len(responses)}ê°œ ìƒ˜í”Œ í‰ê°€ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdba868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ê²°ê³¼ ìš”ì•½\n",
    "import statistics\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“ˆ í‰ê°€ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ê° ì§€í‘œë³„ í‰ê·  ê³„ì‚°\n",
    "metrics = [\"coherence\", \"fluency\", \"groundedness\", \"relevance\"]\n",
    "averages = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    scores = [r[metric] for r in evaluation_results if isinstance(r[metric], (int, float))]\n",
    "    if scores:\n",
    "        averages[metric] = statistics.mean(scores)\n",
    "    else:\n",
    "        averages[metric] = \"N/A\"\n",
    "\n",
    "print(f\"\\nğŸ“Š Overall Scores:\")\n",
    "print(f\"   Coherence:    {averages['coherence']:.2f}/5.0\" if isinstance(averages['coherence'], float) else f\"   Coherence:    {averages['coherence']}\")\n",
    "print(f\"   Fluency:      {averages['fluency']:.2f}/5.0\" if isinstance(averages['fluency'], float) else f\"   Fluency:      {averages['fluency']}\")\n",
    "print(f\"   Groundedness: {averages['groundedness']:.2f}/5.0\" if isinstance(averages['groundedness'], float) else f\"   Groundedness: {averages['groundedness']}\")\n",
    "print(f\"   Relevance:    {averages['relevance']:.2f}/5.0\" if isinstance(averages['relevance'], float) else f\"   Relevance:    {averages['relevance']}\")\n",
    "\n",
    "# Pass/Fail ê¸°ì¤€ (4.0 ì´ìƒì´ë©´ Pass)\n",
    "threshold = 3.5\n",
    "passed = sum(1 for r in evaluation_results \n",
    "             if all(isinstance(r[m], (int, float)) and r[m] >= threshold for m in metrics))\n",
    "pass_rate = (passed / len(evaluation_results)) * 100 if evaluation_results else 0\n",
    "\n",
    "print(f\"\\nâœ… Pass Rate: {pass_rate:.1f}% ({passed}/{len(evaluation_results)} samples)\")\n",
    "print(f\"   (ê¸°ì¤€: ëª¨ë“  ì§€í‘œ â‰¥ {threshold})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ’¡ ê¶Œì¥ ì‚¬í•­:\")\n",
    "if averages.get('groundedness', 5) < 4.0:\n",
    "    print(\"   âš ï¸ Groundedness ê°œì„  í•„ìš”: Knowledge Base ë³´ê°• ë˜ëŠ” Instructions ìˆ˜ì •\")\n",
    "if averages.get('relevance', 5) < 4.0:\n",
    "    print(\"   âš ï¸ Relevance ê°œì„  í•„ìš”: ì—ì´ì „íŠ¸ Instructionsë¥¼ ë” ëª…í™•í•˜ê²Œ\")\n",
    "if averages.get('coherence', 5) < 4.0:\n",
    "    print(\"   âš ï¸ Coherence ê°œì„  í•„ìš”: ì‘ë‹µ êµ¬ì¡°í™” ê°€ì´ë“œë¼ì¸ ì¶”ê°€\")\n",
    "if averages.get('fluency', 5) < 4.0:\n",
    "    print(\"   âš ï¸ Fluency ê°œì„  í•„ìš”: ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ê°œì„ \")\n",
    "if pass_rate >= 80:\n",
    "    print(\"   âœ… ì „ì²´ì ìœ¼ë¡œ ì–‘í˜¸í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤!\")\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™” (ì„ íƒì‚¬í•­)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # ì§€í‘œë³„ í‰ê·  ì ìˆ˜ ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "    valid_metrics = {k: v for k, v in averages.items() if isinstance(v, (int, float))}\n",
    "    \n",
    "    if valid_metrics:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(valid_metrics.keys(), valid_metrics.values())\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold})')\n",
    "        plt.ylim(0, 5)\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Evaluation Results Summary')\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nğŸ“Š ì‹œê°í™” ì™„ë£Œ!\")\n",
    "except ImportError:\n",
    "    print(\"\\nğŸ’¡ ì‹œê°í™”ë¥¼ ìœ„í•´ matplotlib ì„¤ì¹˜: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78457323",
   "metadata": {},
   "source": [
    "### Foundry ì œê³µ Evaluator ì „ì²´ ëª©ë¡\n",
    "\n",
    "FoundryëŠ” 6ê°œ ì¹´í…Œê³ ë¦¬, 32ê°œì˜ Evaluatorë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n",
    "\n",
    "| ì¹´í…Œê³ ë¦¬ | Evaluator ì˜ˆì‹œ |\n",
    "|---------|---------------|\n",
    "| **ì¼ë°˜ í’ˆì§ˆ** | CoherenceEvaluator, FluencyEvaluator, QAEvaluator |\n",
    "| **í…ìŠ¤íŠ¸ ìœ ì‚¬ë„** | SimilarityEvaluator, F1ScoreEvaluator, BleuScoreEvaluator |\n",
    "| **RAG** | GroundednessEvaluator, RelevanceEvaluator, RetrievalEvaluator |\n",
    "| **ì—ì´ì „íŠ¸** | IntentResolutionEvaluator, TaskAdherenceEvaluator, ToolCallAccuracyEvaluator |\n",
    "| **ìœ„í—˜/ì•ˆì „** | ViolenceEvaluator, SexualEvaluator, ContentSafetyEvaluator |\n",
    "| **Azure OpenAI Graders** | AzureOpenAILabelGrader, AzureOpenAIGrader |\n",
    "\n",
    "ìì„¸í•œ ë‚´ìš©ì€ [Azure AI Evaluation ë¬¸ì„œ](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-evaluators)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23da8fc",
   "metadata": {},
   "source": [
    "## í‰ê°€ ê¸°ì¤€ ì´í•´\n",
    "\n",
    "FoundryëŠ” ë‹¤ìŒ 4ê°€ì§€ í•µì‹¬ í‰ê°€ ê¸°ì¤€ì„ ì œê³µí•©ë‹ˆë‹¤:\n",
    "\n",
    "| ê¸°ì¤€ | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **Groundedness** | ì‘ë‹µì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸/ì§€ì‹ì— ê¸°ë°˜í•˜ëŠ”ì§€ |\n",
    "| **Relevance** | ì‘ë‹µì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ |\n",
    "| **Coherence** | ì‘ë‹µì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ì„± ìˆëŠ”ì§€ |\n",
    "| **Fluency** | ì‘ë‹µì´ ìì—°ìŠ¤ëŸ½ê³  ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ì§€ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb366367",
   "metadata": {},
   "source": [
    "# ê°„ë‹¨í•œ ì—ì´ì „íŠ¸ í‰ê°€ ì˜ˆì œ\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "test_queries = [\n",
    "    \"Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì„œìš¸ì˜ ì¸êµ¬ëŠ” ëª‡ ëª…ì¸ê°€ìš”?\",\n",
    "    \"ìµœê·¼ AI ê¸°ìˆ  ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "    \"í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‘ë‹µ ìˆ˜ì§‘\n",
    "agent_id = \"<your-agent-id>\"  # âš ï¸ 03-agentsì—ì„œ ìƒì„±í•œ ì—ì´ì „íŠ¸ ID\n",
    "\n",
    "responses = []\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n[ì§ˆë¬¸ {i}/{len(test_queries)}]: {query}\")\n",
    "    \n",
    "    # Thread ìƒì„±\n",
    "    thread = project_client.agents.create_thread()\n",
    "    \n",
    "    # ë©”ì‹œì§€ ì „ì†¡\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=query\n",
    "    )\n",
    "    \n",
    "    # Run ì‹¤í–‰\n",
    "    run = project_client.agents.create_and_process_run(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=agent_id\n",
    "    )\n",
    "    \n",
    "    # ì‘ë‹µ ìˆ˜ì§‘\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    response = messages.data[0].content[0].text.value\n",
    "    \n",
    "    responses.append({\"query\": query, \"response\": response})\n",
    "    print(f\"[ì‘ë‹µ]: {response[:100]}...\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nâœ… {len(test_queries)}ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"\\nğŸ’¡ í¬í„¸ì—ì„œ ë” ìì„¸í•œ í‰ê°€ë¥¼ ì§„í–‰í•˜ì„¸ìš”:\")\n",
    "print(\"   https://ai.azure.com > Build > Evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816d9ed",
   "metadata": {},
   "source": [
    "### ê° ê¸°ì¤€ì´ ì¤‘ìš”í•œ ì´ìœ \n",
    "\n",
    "| Groundedness | Relevance | Coherence | Fluency |\n",
    "|--------------|-----------|-----------|----------|\n",
    "| ì‚¬ìš©ì ì‹ ë¢° í™•ë³´ | ì‚¬ìš©ì ë§Œì¡±ë„ í–¥ìƒ | ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ | ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ |\n",
    "| ë²•ì  ì±…ì„ ìµœì†Œí™” | íš¨ìœ¨ì  ì •ë³´ ì „ë‹¬ | ì „ë¬¸ì  ì´ë¯¸ì§€ | ë¸Œëœë“œ ì´ë¯¸ì§€ ìœ ì§€ |\n",
    "| í—ˆìœ„ ì •ë³´ ë°©ì§€ | ëŒ€í™” íë¦„ ìœ ì§€ | ì‹ ë¢°ì„± í–¥ìƒ | ì´í•´ë„ ì¦ê°€ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2bdd6",
   "metadata": {},
   "source": [
    "## í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "### í‰ê°€ ì‹¤í–‰\n",
    "\n",
    "1. **Submit** ë²„íŠ¼ í´ë¦­\n",
    "2. í‰ê°€ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ì•½ 10-15ë¶„)\n",
    "3. Evaluations í˜ì´ì§€ì—ì„œ ì§„í–‰ ìƒí™© í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47663d80",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ í•´ì„\n",
    "\n",
    "### ëŒ€ê·œëª¨ í‰ê°€ëŠ” Portal ì‚¬ìš© ê¶Œì¥\n",
    "\n",
    "**SDK vs Portal ë¹„êµ:**\n",
    "\n",
    "| ê¸°ëŠ¥ | Python SDK | Azure Portal |\n",
    "|------|-----------|--------------|\n",
    "| ìƒ˜í”Œ ìˆ˜ | ì†Œê·œëª¨ (10-20) | ëŒ€ê·œëª¨ (50-200+) |\n",
    "| ì‹œê°í™” | ì œí•œì  | í’ë¶€í•œ ëŒ€ì‹œë³´ë“œ |\n",
    "| Synthetic ë°ì´í„° | ìˆ˜ë™ ìƒì„± | ìë™ ìƒì„± |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| **Human Evaluation** | ìë™ í‰ê°€ì™€ ë³‘í–‰í•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì œ íŒ¨í„´ ë°œê²¬ || **ê¸°ì¤€ì„  ì ìˆ˜** | Groundedness â‰¥4.0 / ë‚˜ë¨¸ì§€ â‰¥3.5 / Pass rate â‰¥80% || **í‰ê°€ ì£¼ê¸°** | ê°œë°œ ì¤‘: ë§¤ ì—…ë°ì´íŠ¸ / ë°°í¬ ì „: í•„ìˆ˜ / ë°°í¬ í›„: ì£¼ê°„/ì›”ê°„ || **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤** | ì¼ë°˜Â·ë³µì¡Â·ëª¨í˜¸Â·ë‹¤êµ­ì–´ ì§ˆë¬¸ + Edge cases || **ìƒ˜í”Œ ìˆ˜** | ê°œë°œ: 10-20ê°œ / í…ŒìŠ¤íŠ¸: 50-100ê°œ / í”„ë¡œë•ì…˜: 200+ê°œ ||------|----------|| í•­ëª© | ê¶Œì¥ ì‚¬í•­ |### ê¶Œì¥ ì‚¬í•­6. Submit â†’ ê²°ê³¼ í™•ì¸ (10-15ë¶„ ì†Œìš”)5. Criteria: Groundedness, Relevance, Coherence, Fluency ì„ íƒ4. Data: Synthetic generation (50-200 ìƒ˜í”Œ)3. Target: Agent ì„ íƒ (ì˜ˆ: ModelRouterAgent)2. + Create new evaluation í´ë¦­1. https://ai.azure.com â†’ Build â†’ Evaluations**Portalì—ì„œ í‰ê°€í•˜ëŠ” ë°©ë²•:**| í˜‘ì—… | ì–´ë ¤ì›€ | íŒ€ ê³µìœ  ê°€ëŠ¥ || ê²°ê³¼ ê´€ë¦¬ | ë¡œì»¬ ì €ì¥ | í´ë¼ìš°ë“œ ì €ì¥ ë° ê³µìœ  |Pass Rate: 85% (43/50 samples)\n",
    "```\n",
    "\n",
    "**ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­:**\n",
    "- Groundednessê°€ 4.0 ì´í•˜ì¸ ìƒ˜í”Œ ê²€í† \n",
    "- ì‹¤íŒ¨í•œ 7ê°œ ìƒ˜í”Œ ë¶„ì„\n",
    "- Instructions ê°œì„  ë˜ëŠ” Knowledge Base ë³´ê°•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c1da9",
   "metadata": {},
   "source": [
    "## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤\n",
    "\n",
    "- [Azure AI Evaluation ê°œìš”](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability?view=foundry#what-are-evaluators)\n",
    "- [íŒŒìš´ë“œë¦¬ í¬í„¸ì—ì„œ í‰ê°€ ì‹¤í–‰](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/evaluate-generative-ai-app?view=foundry)\n",
    "- [ì—ì´ì „íŠ¸ í‰ê°€](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-evaluators/agent-evaluators?view=foundry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762eea6",
   "metadata": {},
   "source": [
    "## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤\n",
    "\n",
    "- [Azure AI Evaluation ê°œìš”](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability?view=foundry#what-are-evaluators)\n",
    "- [íŒŒìš´ë“œë¦¬ í¬í„¸ì—ì„œ í‰ê°€ ì‹¤í–‰](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/evaluate-generative-ai-app?view=foundry)\n",
    "- [ì—ì´ì „íŠ¸ í‰ê°€](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-evaluators/agent-evaluators?view=foundry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
